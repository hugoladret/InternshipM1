{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-04-26 - Améliorer le réseau\n",
    "On reprend le notebook de la veille et on améliore les performances, avec notamment une séparation correcte des batchs de training et de test. Le réseau convolutionné ne convergeait pas, donc on le rétrécit en un réseau de 3 couches linéaires.\n",
    "\n",
    "On importe les données :\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "train_set = datasets.ImageFolder(root='clouds_easy',\n",
    "                                transform=data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=1)\n",
    "\n",
    "test_set = datasets.ImageFolder(root='clouds_easy_test',\n",
    "                                transform=data_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                             batch_size=4,shuffle=False,\n",
    "                                             num_workers=1)\n",
    "#les 4 thetas qu'on essaie d'apprendre\n",
    "cloud_classes = ('0', 'pi/4', 'pi/2', '3pi/4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche des images du set importé pour vérifier que tout a bien marché :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          pi/2          3pi/4          pi/2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# pour montrer une image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5    #de-normaliser\n",
    "    npimg = img.numpy()    #convertir en array\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# on loop sur un batch\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('          '.join('%s' % cloud_classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant on défini le réseau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=1024, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(32 * 32, 200)\n",
    "            self.fc2 = nn.Linear(200, 200)\n",
    "            self.fc3 = nn.Linear(200, 4)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return F.log_softmax(input=x)\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et l'optimiseur, toujours en SGD mais avec un learning rate 10 fois plus grand. Avec NLLL comme critère, on a rajouté une couche de softmax en sortie pour obtenir des log-proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n",
      "Epoch: 1 [0/2000 (0%)]\tLoss: 1.376896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 [200/2000 (10%)]\tLoss: 1.417318\n",
      "Epoch: 1 [400/2000 (20%)]\tLoss: 1.403120\n",
      "Epoch: 1 [600/2000 (30%)]\tLoss: 1.451331\n",
      "Epoch: 1 [800/2000 (40%)]\tLoss: 1.359284\n",
      "Epoch: 1 [1000/2000 (50%)]\tLoss: 1.409268\n",
      "Epoch: 1 [1200/2000 (60%)]\tLoss: 1.379941\n",
      "Epoch: 1 [1400/2000 (70%)]\tLoss: 1.391172\n",
      "Epoch: 1 [1600/2000 (80%)]\tLoss: 1.288833\n",
      "Epoch: 1 [1800/2000 (90%)]\tLoss: 1.392593\n",
      "Epoch: 2 [0/2000 (0%)]\tLoss: 1.424673\n",
      "Epoch: 2 [200/2000 (10%)]\tLoss: 1.399692\n",
      "Epoch: 2 [400/2000 (20%)]\tLoss: 1.434875\n",
      "Epoch: 2 [600/2000 (30%)]\tLoss: 1.382303\n",
      "Epoch: 2 [800/2000 (40%)]\tLoss: 1.396274\n",
      "Epoch: 2 [1000/2000 (50%)]\tLoss: 1.375587\n",
      "Epoch: 2 [1200/2000 (60%)]\tLoss: 1.297834\n",
      "Epoch: 2 [1400/2000 (70%)]\tLoss: 1.404530\n",
      "Epoch: 2 [1600/2000 (80%)]\tLoss: 1.398978\n",
      "Epoch: 2 [1800/2000 (90%)]\tLoss: 1.379837\n",
      "Epoch: 3 [0/2000 (0%)]\tLoss: 1.423899\n",
      "Epoch: 3 [200/2000 (10%)]\tLoss: 1.395944\n",
      "Epoch: 3 [400/2000 (20%)]\tLoss: 1.340007\n",
      "Epoch: 3 [600/2000 (30%)]\tLoss: 1.370379\n",
      "Epoch: 3 [800/2000 (40%)]\tLoss: 1.413241\n",
      "Epoch: 3 [1000/2000 (50%)]\tLoss: 1.405320\n",
      "Epoch: 3 [1200/2000 (60%)]\tLoss: 1.420851\n",
      "Epoch: 3 [1400/2000 (70%)]\tLoss: 1.410642\n",
      "Epoch: 3 [1600/2000 (80%)]\tLoss: 1.324168\n",
      "Epoch: 3 [1800/2000 (90%)]\tLoss: 1.386197\n",
      "Epoch: 4 [0/2000 (0%)]\tLoss: 1.369373\n",
      "Epoch: 4 [200/2000 (10%)]\tLoss: 1.444255\n",
      "Epoch: 4 [400/2000 (20%)]\tLoss: 1.255204\n",
      "Epoch: 4 [600/2000 (30%)]\tLoss: 1.365020\n",
      "Epoch: 4 [800/2000 (40%)]\tLoss: 1.258838\n",
      "Epoch: 4 [1000/2000 (50%)]\tLoss: 1.276769\n",
      "Epoch: 4 [1200/2000 (60%)]\tLoss: 1.058410\n",
      "Epoch: 4 [1400/2000 (70%)]\tLoss: 1.316173\n",
      "Epoch: 4 [1600/2000 (80%)]\tLoss: 1.145221\n",
      "Epoch: 4 [1800/2000 (90%)]\tLoss: 1.320853\n",
      "Epoch: 5 [0/2000 (0%)]\tLoss: 1.009891\n",
      "Epoch: 5 [200/2000 (10%)]\tLoss: 0.601998\n",
      "Epoch: 5 [400/2000 (20%)]\tLoss: 0.916292\n",
      "Epoch: 5 [600/2000 (30%)]\tLoss: 2.408211\n",
      "Epoch: 5 [800/2000 (40%)]\tLoss: 1.447379\n",
      "Epoch: 5 [1000/2000 (50%)]\tLoss: 0.748683\n",
      "Epoch: 5 [1200/2000 (60%)]\tLoss: 0.452300\n",
      "Epoch: 5 [1400/2000 (70%)]\tLoss: 0.482182\n",
      "Epoch: 5 [1600/2000 (80%)]\tLoss: 1.254108\n",
      "Epoch: 5 [1800/2000 (90%)]\tLoss: 0.479585\n",
      "Epoch: 6 [0/2000 (0%)]\tLoss: 0.409697\n",
      "Epoch: 6 [200/2000 (10%)]\tLoss: 0.885468\n",
      "Epoch: 6 [400/2000 (20%)]\tLoss: 0.432834\n",
      "Epoch: 6 [600/2000 (30%)]\tLoss: 0.444374\n",
      "Epoch: 6 [800/2000 (40%)]\tLoss: 0.508476\n",
      "Epoch: 6 [1000/2000 (50%)]\tLoss: 0.421319\n",
      "Epoch: 6 [1200/2000 (60%)]\tLoss: 0.190666\n",
      "Epoch: 6 [1400/2000 (70%)]\tLoss: 0.332368\n",
      "Epoch: 6 [1600/2000 (80%)]\tLoss: 0.198042\n",
      "Epoch: 6 [1800/2000 (90%)]\tLoss: 0.631757\n",
      "Epoch: 7 [0/2000 (0%)]\tLoss: 0.014925\n",
      "Epoch: 7 [200/2000 (10%)]\tLoss: 0.276841\n",
      "Epoch: 7 [400/2000 (20%)]\tLoss: 0.087521\n",
      "Epoch: 7 [600/2000 (30%)]\tLoss: 0.532578\n",
      "Epoch: 7 [800/2000 (40%)]\tLoss: 0.041119\n",
      "Epoch: 7 [1000/2000 (50%)]\tLoss: 0.693845\n",
      "Epoch: 7 [1200/2000 (60%)]\tLoss: 0.575280\n",
      "Epoch: 7 [1400/2000 (70%)]\tLoss: 0.379140\n",
      "Epoch: 7 [1600/2000 (80%)]\tLoss: 0.328914\n",
      "Epoch: 7 [1800/2000 (90%)]\tLoss: 0.077061\n",
      "Epoch: 8 [0/2000 (0%)]\tLoss: 0.017952\n",
      "Epoch: 8 [200/2000 (10%)]\tLoss: 0.103319\n",
      "Epoch: 8 [400/2000 (20%)]\tLoss: 2.403234\n",
      "Epoch: 8 [600/2000 (30%)]\tLoss: 0.871140\n",
      "Epoch: 8 [800/2000 (40%)]\tLoss: 0.143423\n",
      "Epoch: 8 [1000/2000 (50%)]\tLoss: 0.150768\n",
      "Epoch: 8 [1200/2000 (60%)]\tLoss: 0.018191\n",
      "Epoch: 8 [1400/2000 (70%)]\tLoss: 0.132812\n",
      "Epoch: 8 [1600/2000 (80%)]\tLoss: 0.476301\n",
      "Epoch: 8 [1800/2000 (90%)]\tLoss: 0.030768\n",
      "Epoch: 9 [0/2000 (0%)]\tLoss: 0.057340\n",
      "Epoch: 9 [200/2000 (10%)]\tLoss: 0.000130\n",
      "Epoch: 9 [400/2000 (20%)]\tLoss: 0.109436\n",
      "Epoch: 9 [600/2000 (30%)]\tLoss: 0.580259\n",
      "Epoch: 9 [800/2000 (40%)]\tLoss: 0.293143\n",
      "Epoch: 9 [1000/2000 (50%)]\tLoss: 0.357111\n",
      "Epoch: 9 [1200/2000 (60%)]\tLoss: 0.005912\n",
      "Epoch: 9 [1400/2000 (70%)]\tLoss: 0.008284\n",
      "Epoch: 9 [1600/2000 (80%)]\tLoss: 0.483815\n",
      "Epoch: 9 [1800/2000 (90%)]\tLoss: 0.019162\n",
      "Epoch: 10 [0/2000 (0%)]\tLoss: 0.012245\n",
      "Epoch: 10 [200/2000 (10%)]\tLoss: 0.078488\n",
      "Epoch: 10 [400/2000 (20%)]\tLoss: 0.571829\n",
      "Epoch: 10 [600/2000 (30%)]\tLoss: 0.065757\n",
      "Epoch: 10 [800/2000 (40%)]\tLoss: 0.005559\n",
      "Epoch: 10 [1000/2000 (50%)]\tLoss: 0.226862\n",
      "Epoch: 10 [1200/2000 (60%)]\tLoss: 0.821553\n",
      "Epoch: 10 [1400/2000 (70%)]\tLoss: 0.138740\n",
      "Epoch: 10 [1600/2000 (80%)]\tLoss: 0.008841\n",
      "Epoch: 10 [1800/2000 (90%)]\tLoss: 0.172126\n",
      "Epoch: 11 [0/2000 (0%)]\tLoss: 0.013594\n",
      "Epoch: 11 [200/2000 (10%)]\tLoss: 0.133390\n",
      "Epoch: 11 [400/2000 (20%)]\tLoss: 0.010632\n",
      "Epoch: 11 [600/2000 (30%)]\tLoss: 0.004402\n",
      "Epoch: 11 [800/2000 (40%)]\tLoss: 0.004834\n",
      "Epoch: 11 [1000/2000 (50%)]\tLoss: 0.005779\n",
      "Epoch: 11 [1200/2000 (60%)]\tLoss: 0.045246\n",
      "Epoch: 11 [1400/2000 (70%)]\tLoss: 0.001130\n",
      "Epoch: 11 [1600/2000 (80%)]\tLoss: 0.000626\n",
      "Epoch: 11 [1800/2000 (90%)]\tLoss: 0.146802\n",
      "Epoch: 12 [0/2000 (0%)]\tLoss: 0.004437\n",
      "Epoch: 12 [200/2000 (10%)]\tLoss: 0.000973\n",
      "Epoch: 12 [400/2000 (20%)]\tLoss: 0.001142\n",
      "Epoch: 12 [600/2000 (30%)]\tLoss: 0.000228\n",
      "Epoch: 12 [800/2000 (40%)]\tLoss: 0.000304\n",
      "Epoch: 12 [1000/2000 (50%)]\tLoss: 0.000043\n",
      "Epoch: 12 [1200/2000 (60%)]\tLoss: 0.002040\n",
      "Epoch: 12 [1400/2000 (70%)]\tLoss: 0.011029\n",
      "Epoch: 12 [1600/2000 (80%)]\tLoss: 0.001574\n",
      "Epoch: 12 [1800/2000 (90%)]\tLoss: 0.389350\n",
      "Epoch: 13 [0/2000 (0%)]\tLoss: 0.016764\n",
      "Epoch: 13 [200/2000 (10%)]\tLoss: 0.002981\n",
      "Epoch: 13 [400/2000 (20%)]\tLoss: 0.000932\n",
      "Epoch: 13 [600/2000 (30%)]\tLoss: 0.000135\n",
      "Epoch: 13 [800/2000 (40%)]\tLoss: 0.042512\n",
      "Epoch: 13 [1000/2000 (50%)]\tLoss: 0.008943\n",
      "Epoch: 13 [1200/2000 (60%)]\tLoss: 0.003995\n",
      "Epoch: 13 [1400/2000 (70%)]\tLoss: 0.020160\n",
      "Epoch: 13 [1600/2000 (80%)]\tLoss: 0.003030\n",
      "Epoch: 13 [1800/2000 (90%)]\tLoss: 0.029120\n",
      "Epoch: 14 [0/2000 (0%)]\tLoss: 0.009014\n",
      "Epoch: 14 [200/2000 (10%)]\tLoss: 0.003059\n",
      "Epoch: 14 [400/2000 (20%)]\tLoss: 0.000456\n",
      "Epoch: 14 [600/2000 (30%)]\tLoss: 0.013982\n",
      "Epoch: 14 [800/2000 (40%)]\tLoss: 0.024615\n",
      "Epoch: 14 [1000/2000 (50%)]\tLoss: 0.016323\n",
      "Epoch: 14 [1200/2000 (60%)]\tLoss: 0.006460\n",
      "Epoch: 14 [1400/2000 (70%)]\tLoss: 0.000403\n",
      "Epoch: 14 [1600/2000 (80%)]\tLoss: 0.018562\n",
      "Epoch: 14 [1800/2000 (90%)]\tLoss: 0.002170\n",
      "Epoch: 15 [0/2000 (0%)]\tLoss: 0.017940\n",
      "Epoch: 15 [200/2000 (10%)]\tLoss: 0.006979\n",
      "Epoch: 15 [400/2000 (20%)]\tLoss: 0.063557\n",
      "Epoch: 15 [600/2000 (30%)]\tLoss: 0.000794\n",
      "Epoch: 15 [800/2000 (40%)]\tLoss: 0.000349\n",
      "Epoch: 15 [1000/2000 (50%)]\tLoss: 0.454249\n",
      "Epoch: 15 [1200/2000 (60%)]\tLoss: 0.131333\n",
      "Epoch: 15 [1400/2000 (70%)]\tLoss: 0.015812\n",
      "Epoch: 15 [1600/2000 (80%)]\tLoss: 0.010812\n",
      "Epoch: 15 [1800/2000 (90%)]\tLoss: 0.006732\n",
      "Epoch: 16 [0/2000 (0%)]\tLoss: 0.000546\n",
      "Epoch: 16 [200/2000 (10%)]\tLoss: 0.006256\n",
      "Epoch: 16 [400/2000 (20%)]\tLoss: 0.002682\n",
      "Epoch: 16 [600/2000 (30%)]\tLoss: 0.000757\n",
      "Epoch: 16 [800/2000 (40%)]\tLoss: 0.005964\n",
      "Epoch: 16 [1000/2000 (50%)]\tLoss: 0.006974\n",
      "Epoch: 16 [1200/2000 (60%)]\tLoss: 0.181894\n",
      "Epoch: 16 [1400/2000 (70%)]\tLoss: 0.094056\n",
      "Epoch: 16 [1600/2000 (80%)]\tLoss: 0.017092\n",
      "Epoch: 16 [1800/2000 (90%)]\tLoss: 0.000067\n",
      "Epoch: 17 [0/2000 (0%)]\tLoss: 0.032201\n",
      "Epoch: 17 [200/2000 (10%)]\tLoss: 0.006003\n",
      "Epoch: 17 [400/2000 (20%)]\tLoss: 0.001120\n",
      "Epoch: 17 [600/2000 (30%)]\tLoss: 0.000072\n",
      "Epoch: 17 [800/2000 (40%)]\tLoss: 0.039418\n",
      "Epoch: 17 [1000/2000 (50%)]\tLoss: 0.012246\n",
      "Epoch: 17 [1200/2000 (60%)]\tLoss: 0.002665\n",
      "Epoch: 17 [1400/2000 (70%)]\tLoss: 0.005716\n",
      "Epoch: 17 [1600/2000 (80%)]\tLoss: 0.012830\n",
      "Epoch: 17 [1800/2000 (90%)]\tLoss: 0.033877\n",
      "Epoch: 18 [0/2000 (0%)]\tLoss: 0.000001\n",
      "Epoch: 18 [200/2000 (10%)]\tLoss: 0.069909\n",
      "Epoch: 18 [400/2000 (20%)]\tLoss: 0.002446\n",
      "Epoch: 18 [600/2000 (30%)]\tLoss: 0.015029\n",
      "Epoch: 18 [800/2000 (40%)]\tLoss: 0.017134\n",
      "Epoch: 18 [1000/2000 (50%)]\tLoss: 0.001936\n",
      "Epoch: 18 [1200/2000 (60%)]\tLoss: 0.009921\n",
      "Epoch: 18 [1400/2000 (70%)]\tLoss: 0.001003\n",
      "Epoch: 18 [1600/2000 (80%)]\tLoss: 0.007656\n",
      "Epoch: 18 [1800/2000 (90%)]\tLoss: 0.000054\n",
      "Epoch: 19 [0/2000 (0%)]\tLoss: 0.000077\n",
      "Epoch: 19 [200/2000 (10%)]\tLoss: 0.001401\n",
      "Epoch: 19 [400/2000 (20%)]\tLoss: 0.001207\n",
      "Epoch: 19 [600/2000 (30%)]\tLoss: 0.000270\n",
      "Epoch: 19 [800/2000 (40%)]\tLoss: 0.001334\n",
      "Epoch: 19 [1000/2000 (50%)]\tLoss: 0.000667\n",
      "Epoch: 19 [1200/2000 (60%)]\tLoss: 0.000097\n",
      "Epoch: 19 [1400/2000 (70%)]\tLoss: 0.001822\n",
      "Epoch: 19 [1600/2000 (80%)]\tLoss: 0.000863\n",
      "Epoch: 19 [1800/2000 (90%)]\tLoss: 0.004640\n",
      "Epoch: 20 [0/2000 (0%)]\tLoss: 0.000142\n",
      "Epoch: 20 [200/2000 (10%)]\tLoss: 0.002970\n",
      "Epoch: 20 [400/2000 (20%)]\tLoss: 0.000473\n",
      "Epoch: 20 [600/2000 (30%)]\tLoss: 0.000973\n",
      "Epoch: 20 [800/2000 (40%)]\tLoss: 0.000228\n",
      "Epoch: 20 [1000/2000 (50%)]\tLoss: 0.001072\n",
      "Epoch: 20 [1200/2000 (60%)]\tLoss: 0.000283\n",
      "Epoch: 20 [1400/2000 (70%)]\tLoss: 0.000595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 [1600/2000 (80%)]\tLoss: 0.001326\n",
      "Epoch: 20 [1800/2000 (90%)]\tLoss: 0.000779\n",
      "Epoch: 21 [0/2000 (0%)]\tLoss: 0.001187\n",
      "Epoch: 21 [200/2000 (10%)]\tLoss: 0.000222\n",
      "Epoch: 21 [400/2000 (20%)]\tLoss: 0.000044\n",
      "Epoch: 21 [600/2000 (30%)]\tLoss: 0.000195\n",
      "Epoch: 21 [800/2000 (40%)]\tLoss: 0.000123\n",
      "Epoch: 21 [1000/2000 (50%)]\tLoss: 0.000351\n",
      "Epoch: 21 [1200/2000 (60%)]\tLoss: 0.000787\n",
      "Epoch: 21 [1400/2000 (70%)]\tLoss: 0.000049\n",
      "Epoch: 21 [1600/2000 (80%)]\tLoss: 0.003685\n",
      "Epoch: 21 [1800/2000 (90%)]\tLoss: 0.001767\n",
      "Epoch: 22 [0/2000 (0%)]\tLoss: 0.000822\n",
      "Epoch: 22 [200/2000 (10%)]\tLoss: 0.000081\n",
      "Epoch: 22 [400/2000 (20%)]\tLoss: 0.000040\n",
      "Epoch: 22 [600/2000 (30%)]\tLoss: 0.000613\n",
      "Epoch: 22 [800/2000 (40%)]\tLoss: 0.000226\n",
      "Epoch: 22 [1000/2000 (50%)]\tLoss: 0.000334\n",
      "Epoch: 22 [1200/2000 (60%)]\tLoss: 0.000012\n",
      "Epoch: 22 [1400/2000 (70%)]\tLoss: 0.000859\n",
      "Epoch: 22 [1600/2000 (80%)]\tLoss: 0.000088\n",
      "Epoch: 22 [1800/2000 (90%)]\tLoss: 0.000326\n",
      "Epoch: 23 [0/2000 (0%)]\tLoss: 0.000100\n",
      "Epoch: 23 [200/2000 (10%)]\tLoss: 0.000114\n",
      "Epoch: 23 [400/2000 (20%)]\tLoss: 0.000160\n",
      "Epoch: 23 [600/2000 (30%)]\tLoss: 0.000458\n",
      "Epoch: 23 [800/2000 (40%)]\tLoss: 0.000109\n",
      "Epoch: 23 [1000/2000 (50%)]\tLoss: 0.000358\n",
      "Epoch: 23 [1200/2000 (60%)]\tLoss: 0.000083\n",
      "Epoch: 23 [1400/2000 (70%)]\tLoss: 0.000019\n",
      "Epoch: 23 [1600/2000 (80%)]\tLoss: 0.001070\n",
      "Epoch: 23 [1800/2000 (90%)]\tLoss: 0.000051\n",
      "Epoch: 24 [0/2000 (0%)]\tLoss: 0.000515\n",
      "Epoch: 24 [200/2000 (10%)]\tLoss: 0.000081\n",
      "Epoch: 24 [400/2000 (20%)]\tLoss: 0.000179\n",
      "Epoch: 24 [600/2000 (30%)]\tLoss: 0.001296\n",
      "Epoch: 24 [800/2000 (40%)]\tLoss: 0.001026\n",
      "Epoch: 24 [1000/2000 (50%)]\tLoss: 0.000069\n",
      "Epoch: 24 [1200/2000 (60%)]\tLoss: 0.000020\n",
      "Epoch: 24 [1400/2000 (70%)]\tLoss: 0.000754\n",
      "Epoch: 24 [1600/2000 (80%)]\tLoss: 0.000015\n",
      "Epoch: 24 [1800/2000 (90%)]\tLoss: 0.000011\n",
      "Epoch: 25 [0/2000 (0%)]\tLoss: 0.000092\n",
      "Epoch: 25 [200/2000 (10%)]\tLoss: 0.000758\n",
      "Epoch: 25 [400/2000 (20%)]\tLoss: 0.000405\n",
      "Epoch: 25 [600/2000 (30%)]\tLoss: 0.000014\n",
      "Epoch: 25 [800/2000 (40%)]\tLoss: 0.000114\n",
      "Epoch: 25 [1000/2000 (50%)]\tLoss: 0.000137\n",
      "Epoch: 25 [1200/2000 (60%)]\tLoss: 0.001590\n",
      "Epoch: 25 [1400/2000 (70%)]\tLoss: 0.000170\n",
      "Epoch: 25 [1600/2000 (80%)]\tLoss: 0.000139\n",
      "Epoch: 25 [1800/2000 (90%)]\tLoss: 0.000025\n",
      "Epoch: 26 [0/2000 (0%)]\tLoss: 0.000168\n",
      "Epoch: 26 [200/2000 (10%)]\tLoss: 0.000212\n",
      "Epoch: 26 [400/2000 (20%)]\tLoss: 0.000353\n",
      "Epoch: 26 [600/2000 (30%)]\tLoss: 0.000114\n",
      "Epoch: 26 [800/2000 (40%)]\tLoss: 0.000052\n",
      "Epoch: 26 [1000/2000 (50%)]\tLoss: 0.001040\n",
      "Epoch: 26 [1200/2000 (60%)]\tLoss: 0.000272\n",
      "Epoch: 26 [1400/2000 (70%)]\tLoss: 0.000383\n",
      "Epoch: 26 [1600/2000 (80%)]\tLoss: 0.000140\n",
      "Epoch: 26 [1800/2000 (90%)]\tLoss: 0.000031\n",
      "Epoch: 27 [0/2000 (0%)]\tLoss: 0.000000\n",
      "Epoch: 27 [200/2000 (10%)]\tLoss: 0.000029\n",
      "Epoch: 27 [400/2000 (20%)]\tLoss: 0.000721\n",
      "Epoch: 27 [600/2000 (30%)]\tLoss: 0.000250\n",
      "Epoch: 27 [800/2000 (40%)]\tLoss: 0.000016\n",
      "Epoch: 27 [1000/2000 (50%)]\tLoss: 0.000449\n",
      "Epoch: 27 [1200/2000 (60%)]\tLoss: 0.000206\n",
      "Epoch: 27 [1400/2000 (70%)]\tLoss: 0.001478\n",
      "Epoch: 27 [1600/2000 (80%)]\tLoss: 0.000183\n",
      "Epoch: 27 [1800/2000 (90%)]\tLoss: 0.000741\n",
      "Epoch: 28 [0/2000 (0%)]\tLoss: 0.000054\n",
      "Epoch: 28 [200/2000 (10%)]\tLoss: 0.000057\n",
      "Epoch: 28 [400/2000 (20%)]\tLoss: 0.000021\n",
      "Epoch: 28 [600/2000 (30%)]\tLoss: 0.000126\n",
      "Epoch: 28 [800/2000 (40%)]\tLoss: 0.000061\n",
      "Epoch: 28 [1000/2000 (50%)]\tLoss: 0.000077\n",
      "Epoch: 28 [1200/2000 (60%)]\tLoss: 0.000001\n",
      "Epoch: 28 [1400/2000 (70%)]\tLoss: 0.000035\n",
      "Epoch: 28 [1600/2000 (80%)]\tLoss: 0.000392\n",
      "Epoch: 28 [1800/2000 (90%)]\tLoss: 0.000022\n",
      "Epoch: 29 [0/2000 (0%)]\tLoss: 0.000059\n",
      "Epoch: 29 [200/2000 (10%)]\tLoss: 0.000213\n",
      "Epoch: 29 [400/2000 (20%)]\tLoss: 0.000011\n",
      "Epoch: 29 [600/2000 (30%)]\tLoss: 0.000049\n",
      "Epoch: 29 [800/2000 (40%)]\tLoss: 0.000254\n",
      "Epoch: 29 [1000/2000 (50%)]\tLoss: 0.000010\n",
      "Epoch: 29 [1200/2000 (60%)]\tLoss: 0.000041\n",
      "Epoch: 29 [1400/2000 (70%)]\tLoss: 0.000688\n",
      "Epoch: 29 [1600/2000 (80%)]\tLoss: 0.000067\n",
      "Epoch: 29 [1800/2000 (90%)]\tLoss: 0.000036\n",
      "Epoch: 30 [0/2000 (0%)]\tLoss: 0.000035\n",
      "Epoch: 30 [200/2000 (10%)]\tLoss: 0.000010\n",
      "Epoch: 30 [400/2000 (20%)]\tLoss: 0.000048\n",
      "Epoch: 30 [600/2000 (30%)]\tLoss: 0.000069\n",
      "Epoch: 30 [800/2000 (40%)]\tLoss: 0.000145\n",
      "Epoch: 30 [1000/2000 (50%)]\tLoss: 0.000133\n",
      "Epoch: 30 [1200/2000 (60%)]\tLoss: 0.000176\n",
      "Epoch: 30 [1400/2000 (70%)]\tLoss: 0.000018\n",
      "Epoch: 30 [1600/2000 (80%)]\tLoss: 0.000083\n",
      "Epoch: 30 [1800/2000 (90%)]\tLoss: 0.000026\n",
      "Epoch: 31 [0/2000 (0%)]\tLoss: 0.000030\n",
      "Epoch: 31 [200/2000 (10%)]\tLoss: 0.000013\n",
      "Epoch: 31 [400/2000 (20%)]\tLoss: 0.000127\n",
      "Epoch: 31 [600/2000 (30%)]\tLoss: 0.000479\n",
      "Epoch: 31 [800/2000 (40%)]\tLoss: 0.000013\n",
      "Epoch: 31 [1000/2000 (50%)]\tLoss: 0.000031\n",
      "Epoch: 31 [1200/2000 (60%)]\tLoss: 0.000200\n",
      "Epoch: 31 [1400/2000 (70%)]\tLoss: 0.000199\n",
      "Epoch: 31 [1600/2000 (80%)]\tLoss: 0.000031\n",
      "Epoch: 31 [1800/2000 (90%)]\tLoss: 0.000026\n",
      "Epoch: 32 [0/2000 (0%)]\tLoss: 0.000073\n",
      "Epoch: 32 [200/2000 (10%)]\tLoss: 0.000360\n",
      "Epoch: 32 [400/2000 (20%)]\tLoss: 0.000428\n",
      "Epoch: 32 [600/2000 (30%)]\tLoss: 0.000001\n",
      "Epoch: 32 [800/2000 (40%)]\tLoss: 0.000074\n",
      "Epoch: 32 [1000/2000 (50%)]\tLoss: 0.000083\n",
      "Epoch: 32 [1200/2000 (60%)]\tLoss: 0.000196\n",
      "Epoch: 32 [1400/2000 (70%)]\tLoss: 0.000469\n",
      "Epoch: 32 [1600/2000 (80%)]\tLoss: 0.000067\n",
      "Epoch: 32 [1800/2000 (90%)]\tLoss: 0.000003\n",
      "Epoch: 33 [0/2000 (0%)]\tLoss: 0.000258\n",
      "Epoch: 33 [200/2000 (10%)]\tLoss: 0.000044\n",
      "Epoch: 33 [400/2000 (20%)]\tLoss: 0.000024\n",
      "Epoch: 33 [600/2000 (30%)]\tLoss: 0.000022\n",
      "Epoch: 33 [800/2000 (40%)]\tLoss: 0.000154\n",
      "Epoch: 33 [1000/2000 (50%)]\tLoss: 0.000108\n",
      "Epoch: 33 [1200/2000 (60%)]\tLoss: 0.000173\n",
      "Epoch: 33 [1400/2000 (70%)]\tLoss: 0.001002\n",
      "Epoch: 33 [1600/2000 (80%)]\tLoss: 0.000113\n",
      "Epoch: 33 [1800/2000 (90%)]\tLoss: 0.000988\n",
      "Epoch: 34 [0/2000 (0%)]\tLoss: 0.000038\n",
      "Epoch: 34 [200/2000 (10%)]\tLoss: 0.000011\n",
      "Epoch: 34 [400/2000 (20%)]\tLoss: 0.000070\n",
      "Epoch: 34 [600/2000 (30%)]\tLoss: 0.000261\n",
      "Epoch: 34 [800/2000 (40%)]\tLoss: 0.000106\n",
      "Epoch: 34 [1000/2000 (50%)]\tLoss: 0.000219\n",
      "Epoch: 34 [1200/2000 (60%)]\tLoss: 0.000233\n",
      "Epoch: 34 [1400/2000 (70%)]\tLoss: 0.000183\n",
      "Epoch: 34 [1600/2000 (80%)]\tLoss: 0.000312\n",
      "Epoch: 34 [1800/2000 (90%)]\tLoss: 0.000022\n",
      "Epoch: 35 [0/2000 (0%)]\tLoss: 0.000441\n",
      "Epoch: 35 [200/2000 (10%)]\tLoss: 0.000030\n",
      "Epoch: 35 [400/2000 (20%)]\tLoss: 0.000051\n",
      "Epoch: 35 [600/2000 (30%)]\tLoss: 0.000080\n",
      "Epoch: 35 [800/2000 (40%)]\tLoss: 0.000004\n",
      "Epoch: 35 [1000/2000 (50%)]\tLoss: 0.000004\n",
      "Epoch: 35 [1200/2000 (60%)]\tLoss: 0.000031\n",
      "Epoch: 35 [1400/2000 (70%)]\tLoss: 0.000016\n",
      "Epoch: 35 [1600/2000 (80%)]\tLoss: 0.000001\n",
      "Epoch: 35 [1800/2000 (90%)]\tLoss: 0.000543\n",
      "Epoch: 36 [0/2000 (0%)]\tLoss: 0.000486\n",
      "Epoch: 36 [200/2000 (10%)]\tLoss: 0.000021\n",
      "Epoch: 36 [400/2000 (20%)]\tLoss: 0.000105\n",
      "Epoch: 36 [600/2000 (30%)]\tLoss: 0.000000\n",
      "Epoch: 36 [800/2000 (40%)]\tLoss: 0.000002\n",
      "Epoch: 36 [1000/2000 (50%)]\tLoss: 0.000039\n",
      "Epoch: 36 [1200/2000 (60%)]\tLoss: 0.000693\n",
      "Epoch: 36 [1400/2000 (70%)]\tLoss: 0.000036\n",
      "Epoch: 36 [1600/2000 (80%)]\tLoss: 0.000054\n",
      "Epoch: 36 [1800/2000 (90%)]\tLoss: 0.000060\n",
      "Epoch: 37 [0/2000 (0%)]\tLoss: 0.000113\n",
      "Epoch: 37 [200/2000 (10%)]\tLoss: 0.000036\n",
      "Epoch: 37 [400/2000 (20%)]\tLoss: 0.000116\n",
      "Epoch: 37 [600/2000 (30%)]\tLoss: 0.000026\n",
      "Epoch: 37 [800/2000 (40%)]\tLoss: 0.000007\n",
      "Epoch: 37 [1000/2000 (50%)]\tLoss: 0.000088\n",
      "Epoch: 37 [1200/2000 (60%)]\tLoss: 0.000169\n",
      "Epoch: 37 [1400/2000 (70%)]\tLoss: 0.000002\n",
      "Epoch: 37 [1600/2000 (80%)]\tLoss: 0.000001\n",
      "Epoch: 37 [1800/2000 (90%)]\tLoss: 0.000032\n",
      "Epoch: 38 [0/2000 (0%)]\tLoss: 0.000413\n",
      "Epoch: 38 [200/2000 (10%)]\tLoss: 0.000032\n",
      "Epoch: 38 [400/2000 (20%)]\tLoss: 0.000070\n",
      "Epoch: 38 [600/2000 (30%)]\tLoss: 0.000233\n",
      "Epoch: 38 [800/2000 (40%)]\tLoss: 0.000078\n",
      "Epoch: 38 [1000/2000 (50%)]\tLoss: 0.000234\n",
      "Epoch: 38 [1200/2000 (60%)]\tLoss: 0.000064\n",
      "Epoch: 38 [1400/2000 (70%)]\tLoss: 0.000323\n",
      "Epoch: 38 [1600/2000 (80%)]\tLoss: 0.000027\n",
      "Epoch: 38 [1800/2000 (90%)]\tLoss: 0.000088\n",
      "Epoch: 39 [0/2000 (0%)]\tLoss: 0.000076\n",
      "Epoch: 39 [200/2000 (10%)]\tLoss: 0.000106\n",
      "Epoch: 39 [400/2000 (20%)]\tLoss: 0.000185\n",
      "Epoch: 39 [600/2000 (30%)]\tLoss: 0.000318\n",
      "Epoch: 39 [800/2000 (40%)]\tLoss: 0.000011\n",
      "Epoch: 39 [1000/2000 (50%)]\tLoss: 0.000068\n",
      "Epoch: 39 [1200/2000 (60%)]\tLoss: 0.000133\n",
      "Epoch: 39 [1400/2000 (70%)]\tLoss: 0.000015\n",
      "Epoch: 39 [1600/2000 (80%)]\tLoss: 0.000061\n",
      "Epoch: 39 [1800/2000 (90%)]\tLoss: 0.000052\n",
      "Epoch: 40 [0/2000 (0%)]\tLoss: 0.000194\n",
      "Epoch: 40 [200/2000 (10%)]\tLoss: 0.000004\n",
      "Epoch: 40 [400/2000 (20%)]\tLoss: 0.000023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 [600/2000 (30%)]\tLoss: 0.000150\n",
      "Epoch: 40 [800/2000 (40%)]\tLoss: 0.000033\n",
      "Epoch: 40 [1000/2000 (50%)]\tLoss: 0.000098\n",
      "Epoch: 40 [1200/2000 (60%)]\tLoss: 0.000043\n",
      "Epoch: 40 [1400/2000 (70%)]\tLoss: 0.000111\n",
      "Epoch: 40 [1600/2000 (80%)]\tLoss: 0.000043\n",
      "Epoch: 40 [1800/2000 (90%)]\tLoss: 0.000135\n",
      "Epoch: 41 [0/2000 (0%)]\tLoss: 0.000023\n",
      "Epoch: 41 [200/2000 (10%)]\tLoss: 0.000015\n",
      "Epoch: 41 [400/2000 (20%)]\tLoss: 0.000003\n",
      "Epoch: 41 [600/2000 (30%)]\tLoss: 0.000037\n",
      "Epoch: 41 [800/2000 (40%)]\tLoss: 0.000100\n",
      "Epoch: 41 [1000/2000 (50%)]\tLoss: 0.000013\n",
      "Epoch: 41 [1200/2000 (60%)]\tLoss: 0.000047\n",
      "Epoch: 41 [1400/2000 (70%)]\tLoss: 0.000023\n",
      "Epoch: 41 [1600/2000 (80%)]\tLoss: 0.000241\n",
      "Epoch: 41 [1800/2000 (90%)]\tLoss: 0.000053\n",
      "Epoch: 42 [0/2000 (0%)]\tLoss: 0.000017\n",
      "Epoch: 42 [200/2000 (10%)]\tLoss: 0.000002\n",
      "Epoch: 42 [400/2000 (20%)]\tLoss: 0.000041\n",
      "Epoch: 42 [600/2000 (30%)]\tLoss: 0.000016\n",
      "Epoch: 42 [800/2000 (40%)]\tLoss: 0.000024\n",
      "Epoch: 42 [1000/2000 (50%)]\tLoss: 0.000029\n",
      "Epoch: 42 [1200/2000 (60%)]\tLoss: 0.000018\n",
      "Epoch: 42 [1400/2000 (70%)]\tLoss: 0.000141\n",
      "Epoch: 42 [1600/2000 (80%)]\tLoss: 0.000030\n",
      "Epoch: 42 [1800/2000 (90%)]\tLoss: 0.000019\n",
      "Epoch: 43 [0/2000 (0%)]\tLoss: 0.000077\n",
      "Epoch: 43 [200/2000 (10%)]\tLoss: 0.000009\n",
      "Epoch: 43 [400/2000 (20%)]\tLoss: 0.000009\n",
      "Epoch: 43 [600/2000 (30%)]\tLoss: 0.000032\n",
      "Epoch: 43 [800/2000 (40%)]\tLoss: 0.000124\n",
      "Epoch: 43 [1000/2000 (50%)]\tLoss: 0.000231\n",
      "Epoch: 43 [1200/2000 (60%)]\tLoss: 0.000019\n",
      "Epoch: 43 [1400/2000 (70%)]\tLoss: 0.000002\n",
      "Epoch: 43 [1600/2000 (80%)]\tLoss: 0.000090\n",
      "Epoch: 43 [1800/2000 (90%)]\tLoss: 0.000070\n",
      "Epoch: 44 [0/2000 (0%)]\tLoss: 0.000030\n",
      "Epoch: 44 [200/2000 (10%)]\tLoss: 0.000164\n",
      "Epoch: 44 [400/2000 (20%)]\tLoss: 0.000029\n",
      "Epoch: 44 [600/2000 (30%)]\tLoss: 0.000209\n",
      "Epoch: 44 [800/2000 (40%)]\tLoss: 0.000562\n",
      "Epoch: 44 [1000/2000 (50%)]\tLoss: 0.000375\n",
      "Epoch: 44 [1200/2000 (60%)]\tLoss: 0.000016\n",
      "Epoch: 44 [1400/2000 (70%)]\tLoss: 0.000176\n",
      "Epoch: 44 [1600/2000 (80%)]\tLoss: 0.000022\n",
      "Epoch: 44 [1800/2000 (90%)]\tLoss: 0.000041\n",
      "Epoch: 45 [0/2000 (0%)]\tLoss: 0.000002\n",
      "Epoch: 45 [200/2000 (10%)]\tLoss: 0.000242\n",
      "Epoch: 45 [400/2000 (20%)]\tLoss: 0.000138\n",
      "Epoch: 45 [600/2000 (30%)]\tLoss: 0.000114\n",
      "Epoch: 45 [800/2000 (40%)]\tLoss: 0.000041\n",
      "Epoch: 45 [1000/2000 (50%)]\tLoss: 0.000008\n",
      "Epoch: 45 [1200/2000 (60%)]\tLoss: 0.000004\n",
      "Epoch: 45 [1400/2000 (70%)]\tLoss: 0.000140\n",
      "Epoch: 45 [1600/2000 (80%)]\tLoss: 0.000041\n",
      "Epoch: 45 [1800/2000 (90%)]\tLoss: 0.000021\n",
      "Epoch: 46 [0/2000 (0%)]\tLoss: 0.000125\n",
      "Epoch: 46 [200/2000 (10%)]\tLoss: 0.000019\n",
      "Epoch: 46 [400/2000 (20%)]\tLoss: 0.000062\n",
      "Epoch: 46 [600/2000 (30%)]\tLoss: 0.000033\n",
      "Epoch: 46 [800/2000 (40%)]\tLoss: 0.000069\n",
      "Epoch: 46 [1000/2000 (50%)]\tLoss: 0.000135\n",
      "Epoch: 46 [1200/2000 (60%)]\tLoss: 0.000026\n",
      "Epoch: 46 [1400/2000 (70%)]\tLoss: 0.000371\n",
      "Epoch: 46 [1600/2000 (80%)]\tLoss: 0.000188\n",
      "Epoch: 46 [1800/2000 (90%)]\tLoss: 0.000030\n",
      "Epoch: 47 [0/2000 (0%)]\tLoss: 0.000584\n",
      "Epoch: 47 [200/2000 (10%)]\tLoss: 0.000266\n",
      "Epoch: 47 [400/2000 (20%)]\tLoss: 0.000025\n",
      "Epoch: 47 [600/2000 (30%)]\tLoss: 0.000006\n",
      "Epoch: 47 [800/2000 (40%)]\tLoss: 0.000005\n",
      "Epoch: 47 [1000/2000 (50%)]\tLoss: 0.000004\n",
      "Epoch: 47 [1200/2000 (60%)]\tLoss: 0.000067\n",
      "Epoch: 47 [1400/2000 (70%)]\tLoss: 0.000000\n",
      "Epoch: 47 [1600/2000 (80%)]\tLoss: 0.000094\n",
      "Epoch: 47 [1800/2000 (90%)]\tLoss: 0.000013\n",
      "Epoch: 48 [0/2000 (0%)]\tLoss: 0.000594\n",
      "Epoch: 48 [200/2000 (10%)]\tLoss: 0.000023\n",
      "Epoch: 48 [400/2000 (20%)]\tLoss: 0.000404\n",
      "Epoch: 48 [600/2000 (30%)]\tLoss: 0.000029\n",
      "Epoch: 48 [800/2000 (40%)]\tLoss: 0.000195\n",
      "Epoch: 48 [1000/2000 (50%)]\tLoss: 0.000001\n",
      "Epoch: 48 [1200/2000 (60%)]\tLoss: 0.000003\n",
      "Epoch: 48 [1400/2000 (70%)]\tLoss: 0.000009\n",
      "Epoch: 48 [1600/2000 (80%)]\tLoss: 0.000041\n",
      "Epoch: 48 [1800/2000 (90%)]\tLoss: 0.000005\n",
      "Epoch: 49 [0/2000 (0%)]\tLoss: 0.000003\n",
      "Epoch: 49 [200/2000 (10%)]\tLoss: 0.000014\n",
      "Epoch: 49 [400/2000 (20%)]\tLoss: 0.000187\n",
      "Epoch: 49 [600/2000 (30%)]\tLoss: 0.000415\n",
      "Epoch: 49 [800/2000 (40%)]\tLoss: 0.000014\n",
      "Epoch: 49 [1000/2000 (50%)]\tLoss: 0.000046\n",
      "Epoch: 49 [1200/2000 (60%)]\tLoss: 0.000020\n",
      "Epoch: 49 [1400/2000 (70%)]\tLoss: 0.000008\n",
      "Epoch: 49 [1600/2000 (80%)]\tLoss: 0.000071\n",
      "Epoch: 49 [1800/2000 (90%)]\tLoss: 0.000006\n",
      "Epoch: 50 [0/2000 (0%)]\tLoss: 0.000000\n",
      "Epoch: 50 [200/2000 (10%)]\tLoss: 0.000039\n",
      "Epoch: 50 [400/2000 (20%)]\tLoss: 0.000286\n",
      "Epoch: 50 [600/2000 (30%)]\tLoss: 0.000001\n",
      "Epoch: 50 [800/2000 (40%)]\tLoss: 0.000073\n",
      "Epoch: 50 [1000/2000 (50%)]\tLoss: 0.000125\n",
      "Epoch: 50 [1200/2000 (60%)]\tLoss: 0.000011\n",
      "Epoch: 50 [1400/2000 (70%)]\tLoss: 0.000087\n",
      "Epoch: 50 [1600/2000 (80%)]\tLoss: 0.000079\n",
      "Epoch: 50 [1800/2000 (90%)]\tLoss: 0.000006\n",
      "Finished training in  544.354 seconds \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(\"Started training\")\n",
    "\n",
    "epochs = 50\n",
    "print_interval = 50 #prints every p_i*4\n",
    "tempo = []\n",
    "acc = []\n",
    "\n",
    "for epoch in range(epochs):  # nbr epochs\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): #nbr batch,in,out\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        #On resize pour la sortie\n",
    "        data = data.view(-1, 32*32)\n",
    "\n",
    "        #init l'entrainement\n",
    "        optimizer.zero_grad()\n",
    "        net_out = model(data)\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #afficher la progression\n",
    "        if batch_idx % print_interval == 0:\n",
    "            #le print statement le plus illisible du monde\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "    tempo.append(epoch)\n",
    "    acc.append(loss.data[0])\n",
    "    \n",
    "print(\"Finished training in  %.3f seconds \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant on teste :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 96/100 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    \n",
    "    #rescale\n",
    "    data = data.view(-1, 32 * 32)\n",
    "    net_out = model(data)\n",
    "    \n",
    "    #somme des pertes du batch\n",
    "    test_loss += criterion(net_out, target).data[0]\n",
    "    pred = net_out.data.max(1)[1] #prediction\n",
    "    correct += pred.eq(target.data).sum() #output du réseau\n",
    "\n",
    "test_loss /= len(test_loader.dataset) #loss = loss/length set\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96% de précision en 50 epochs, on sauvegarde le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"MODEL_trainEASY_pytorchMCV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa89f4b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#joli plot du loss en fonction de l'epoch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tempo, acc)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss variation - Easy training')\n",
    "plt.savefig('Loss_easytraining.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant pour le set moyen, qui obtient 68% de précision :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n",
      "Epoch: 1 [0/2000 (0%)]\tLoss: 1.374355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [200/2000 (10%)]\tLoss: 1.359179\n",
      "Epoch: 1 [400/2000 (20%)]\tLoss: 1.361182\n",
      "Epoch: 1 [600/2000 (30%)]\tLoss: 1.358648\n",
      "Epoch: 1 [800/2000 (40%)]\tLoss: 1.468187\n",
      "Epoch: 1 [1000/2000 (50%)]\tLoss: 1.383861\n",
      "Epoch: 1 [1200/2000 (60%)]\tLoss: 1.454609\n",
      "Epoch: 1 [1400/2000 (70%)]\tLoss: 1.488600\n",
      "Epoch: 1 [1600/2000 (80%)]\tLoss: 1.515073\n",
      "Epoch: 1 [1800/2000 (90%)]\tLoss: 1.302717\n",
      "Epoch: 2 [0/2000 (0%)]\tLoss: 1.411291\n",
      "Epoch: 2 [200/2000 (10%)]\tLoss: 1.393153\n",
      "Epoch: 2 [400/2000 (20%)]\tLoss: 1.368572\n",
      "Epoch: 2 [600/2000 (30%)]\tLoss: 1.349585\n",
      "Epoch: 2 [800/2000 (40%)]\tLoss: 1.385220\n",
      "Epoch: 2 [1000/2000 (50%)]\tLoss: 1.368461\n",
      "Epoch: 2 [1200/2000 (60%)]\tLoss: 1.500476\n",
      "Epoch: 2 [1400/2000 (70%)]\tLoss: 1.377312\n",
      "Epoch: 2 [1600/2000 (80%)]\tLoss: 1.352135\n",
      "Epoch: 2 [1800/2000 (90%)]\tLoss: 1.387257\n",
      "Epoch: 3 [0/2000 (0%)]\tLoss: 1.343654\n",
      "Epoch: 3 [200/2000 (10%)]\tLoss: 1.390976\n",
      "Epoch: 3 [400/2000 (20%)]\tLoss: 1.431192\n",
      "Epoch: 3 [600/2000 (30%)]\tLoss: 1.356247\n",
      "Epoch: 3 [800/2000 (40%)]\tLoss: 1.370790\n",
      "Epoch: 3 [1000/2000 (50%)]\tLoss: 1.359474\n",
      "Epoch: 3 [1200/2000 (60%)]\tLoss: 1.416197\n",
      "Epoch: 3 [1400/2000 (70%)]\tLoss: 1.363455\n",
      "Epoch: 3 [1600/2000 (80%)]\tLoss: 1.342827\n",
      "Epoch: 3 [1800/2000 (90%)]\tLoss: 1.373145\n",
      "Epoch: 4 [0/2000 (0%)]\tLoss: 1.430783\n",
      "Epoch: 4 [200/2000 (10%)]\tLoss: 1.436877\n",
      "Epoch: 4 [400/2000 (20%)]\tLoss: 1.401896\n",
      "Epoch: 4 [600/2000 (30%)]\tLoss: 1.416980\n",
      "Epoch: 4 [800/2000 (40%)]\tLoss: 1.381072\n",
      "Epoch: 4 [1000/2000 (50%)]\tLoss: 1.430609\n",
      "Epoch: 4 [1200/2000 (60%)]\tLoss: 1.299034\n",
      "Epoch: 4 [1400/2000 (70%)]\tLoss: 1.385697\n",
      "Epoch: 4 [1600/2000 (80%)]\tLoss: 1.411461\n",
      "Epoch: 4 [1800/2000 (90%)]\tLoss: 1.337444\n",
      "Epoch: 5 [0/2000 (0%)]\tLoss: 1.412928\n",
      "Epoch: 5 [200/2000 (10%)]\tLoss: 1.396828\n",
      "Epoch: 5 [400/2000 (20%)]\tLoss: 1.378247\n",
      "Epoch: 5 [600/2000 (30%)]\tLoss: 1.315613\n",
      "Epoch: 5 [800/2000 (40%)]\tLoss: 1.330202\n",
      "Epoch: 5 [1000/2000 (50%)]\tLoss: 1.240185\n",
      "Epoch: 5 [1200/2000 (60%)]\tLoss: 1.443874\n",
      "Epoch: 5 [1400/2000 (70%)]\tLoss: 1.372040\n",
      "Epoch: 5 [1600/2000 (80%)]\tLoss: 1.403440\n",
      "Epoch: 5 [1800/2000 (90%)]\tLoss: 1.378512\n",
      "Epoch: 6 [0/2000 (0%)]\tLoss: 1.369120\n",
      "Epoch: 6 [200/2000 (10%)]\tLoss: 1.383508\n",
      "Epoch: 6 [400/2000 (20%)]\tLoss: 1.505033\n",
      "Epoch: 6 [600/2000 (30%)]\tLoss: 1.386674\n",
      "Epoch: 6 [800/2000 (40%)]\tLoss: 1.255873\n",
      "Epoch: 6 [1000/2000 (50%)]\tLoss: 1.455749\n",
      "Epoch: 6 [1200/2000 (60%)]\tLoss: 1.403748\n",
      "Epoch: 6 [1400/2000 (70%)]\tLoss: 1.402673\n",
      "Epoch: 6 [1600/2000 (80%)]\tLoss: 1.403412\n",
      "Epoch: 6 [1800/2000 (90%)]\tLoss: 1.503983\n",
      "Epoch: 7 [0/2000 (0%)]\tLoss: 1.378592\n",
      "Epoch: 7 [200/2000 (10%)]\tLoss: 1.406409\n",
      "Epoch: 7 [400/2000 (20%)]\tLoss: 1.454076\n",
      "Epoch: 7 [600/2000 (30%)]\tLoss: 1.353127\n",
      "Epoch: 7 [800/2000 (40%)]\tLoss: 1.348543\n",
      "Epoch: 7 [1000/2000 (50%)]\tLoss: 1.218119\n",
      "Epoch: 7 [1200/2000 (60%)]\tLoss: 1.416145\n",
      "Epoch: 7 [1400/2000 (70%)]\tLoss: 1.345432\n",
      "Epoch: 7 [1600/2000 (80%)]\tLoss: 1.397136\n",
      "Epoch: 7 [1800/2000 (90%)]\tLoss: 1.398084\n",
      "Epoch: 8 [0/2000 (0%)]\tLoss: 1.406008\n",
      "Epoch: 8 [200/2000 (10%)]\tLoss: 1.436479\n",
      "Epoch: 8 [400/2000 (20%)]\tLoss: 1.482209\n",
      "Epoch: 8 [600/2000 (30%)]\tLoss: 1.545111\n",
      "Epoch: 8 [800/2000 (40%)]\tLoss: 1.301674\n",
      "Epoch: 8 [1000/2000 (50%)]\tLoss: 1.387554\n",
      "Epoch: 8 [1200/2000 (60%)]\tLoss: 1.116184\n",
      "Epoch: 8 [1400/2000 (70%)]\tLoss: 1.540877\n",
      "Epoch: 8 [1600/2000 (80%)]\tLoss: 1.308869\n",
      "Epoch: 8 [1800/2000 (90%)]\tLoss: 1.379334\n",
      "Epoch: 9 [0/2000 (0%)]\tLoss: 0.912042\n",
      "Epoch: 9 [200/2000 (10%)]\tLoss: 1.250031\n",
      "Epoch: 9 [400/2000 (20%)]\tLoss: 1.112579\n",
      "Epoch: 9 [600/2000 (30%)]\tLoss: 1.893712\n",
      "Epoch: 9 [800/2000 (40%)]\tLoss: 1.119493\n",
      "Epoch: 9 [1000/2000 (50%)]\tLoss: 1.141411\n",
      "Epoch: 9 [1200/2000 (60%)]\tLoss: 1.450045\n",
      "Epoch: 9 [1400/2000 (70%)]\tLoss: 1.095513\n",
      "Epoch: 9 [1600/2000 (80%)]\tLoss: 1.209806\n",
      "Epoch: 9 [1800/2000 (90%)]\tLoss: 1.028613\n",
      "Epoch: 10 [0/2000 (0%)]\tLoss: 0.633010\n",
      "Epoch: 10 [200/2000 (10%)]\tLoss: 0.914940\n",
      "Epoch: 10 [400/2000 (20%)]\tLoss: 1.449704\n",
      "Epoch: 10 [600/2000 (30%)]\tLoss: 1.220566\n",
      "Epoch: 10 [800/2000 (40%)]\tLoss: 1.065579\n",
      "Epoch: 10 [1000/2000 (50%)]\tLoss: 1.054419\n",
      "Epoch: 10 [1200/2000 (60%)]\tLoss: 1.576336\n",
      "Epoch: 10 [1400/2000 (70%)]\tLoss: 1.158993\n",
      "Epoch: 10 [1600/2000 (80%)]\tLoss: 2.189494\n",
      "Epoch: 10 [1800/2000 (90%)]\tLoss: 1.621263\n",
      "Epoch: 11 [0/2000 (0%)]\tLoss: 1.007695\n",
      "Epoch: 11 [200/2000 (10%)]\tLoss: 0.960946\n",
      "Epoch: 11 [400/2000 (20%)]\tLoss: 0.655227\n",
      "Epoch: 11 [600/2000 (30%)]\tLoss: 0.823825\n",
      "Epoch: 11 [800/2000 (40%)]\tLoss: 0.871419\n",
      "Epoch: 11 [1000/2000 (50%)]\tLoss: 0.762664\n",
      "Epoch: 11 [1200/2000 (60%)]\tLoss: 0.935259\n",
      "Epoch: 11 [1400/2000 (70%)]\tLoss: 0.943811\n",
      "Epoch: 11 [1600/2000 (80%)]\tLoss: 1.208698\n",
      "Epoch: 11 [1800/2000 (90%)]\tLoss: 1.184289\n",
      "Epoch: 12 [0/2000 (0%)]\tLoss: 1.009659\n",
      "Epoch: 12 [200/2000 (10%)]\tLoss: 0.887195\n",
      "Epoch: 12 [400/2000 (20%)]\tLoss: 0.206155\n",
      "Epoch: 12 [600/2000 (30%)]\tLoss: 0.175081\n",
      "Epoch: 12 [800/2000 (40%)]\tLoss: 0.561830\n",
      "Epoch: 12 [1000/2000 (50%)]\tLoss: 0.717115\n",
      "Epoch: 12 [1200/2000 (60%)]\tLoss: 0.523018\n",
      "Epoch: 12 [1400/2000 (70%)]\tLoss: 0.208864\n",
      "Epoch: 12 [1600/2000 (80%)]\tLoss: 0.399072\n",
      "Epoch: 12 [1800/2000 (90%)]\tLoss: 1.171927\n",
      "Epoch: 13 [0/2000 (0%)]\tLoss: 0.224619\n",
      "Epoch: 13 [200/2000 (10%)]\tLoss: 0.088485\n",
      "Epoch: 13 [400/2000 (20%)]\tLoss: 0.129695\n",
      "Epoch: 13 [600/2000 (30%)]\tLoss: 0.494381\n",
      "Epoch: 13 [800/2000 (40%)]\tLoss: 0.167762\n",
      "Epoch: 13 [1000/2000 (50%)]\tLoss: 0.271281\n",
      "Epoch: 13 [1200/2000 (60%)]\tLoss: 1.459979\n",
      "Epoch: 13 [1400/2000 (70%)]\tLoss: 0.768446\n",
      "Epoch: 13 [1600/2000 (80%)]\tLoss: 0.529905\n",
      "Epoch: 13 [1800/2000 (90%)]\tLoss: 0.532434\n",
      "Epoch: 14 [0/2000 (0%)]\tLoss: 0.188062\n",
      "Epoch: 14 [200/2000 (10%)]\tLoss: 0.677817\n",
      "Epoch: 14 [400/2000 (20%)]\tLoss: 0.449014\n",
      "Epoch: 14 [600/2000 (30%)]\tLoss: 0.022104\n",
      "Epoch: 14 [800/2000 (40%)]\tLoss: 0.051320\n",
      "Epoch: 14 [1000/2000 (50%)]\tLoss: 0.417164\n",
      "Epoch: 14 [1200/2000 (60%)]\tLoss: 0.337659\n",
      "Epoch: 14 [1400/2000 (70%)]\tLoss: 0.430636\n",
      "Epoch: 14 [1600/2000 (80%)]\tLoss: 0.463619\n",
      "Epoch: 14 [1800/2000 (90%)]\tLoss: 0.434796\n",
      "Epoch: 15 [0/2000 (0%)]\tLoss: 0.345342\n",
      "Epoch: 15 [200/2000 (10%)]\tLoss: 0.011972\n",
      "Epoch: 15 [400/2000 (20%)]\tLoss: 0.084059\n",
      "Epoch: 15 [600/2000 (30%)]\tLoss: 0.285726\n",
      "Epoch: 15 [800/2000 (40%)]\tLoss: 0.144466\n",
      "Epoch: 15 [1000/2000 (50%)]\tLoss: 0.828009\n",
      "Epoch: 15 [1200/2000 (60%)]\tLoss: 0.037568\n",
      "Epoch: 15 [1400/2000 (70%)]\tLoss: 0.523267\n",
      "Epoch: 15 [1600/2000 (80%)]\tLoss: 0.929007\n",
      "Epoch: 15 [1800/2000 (90%)]\tLoss: 0.641685\n",
      "Epoch: 16 [0/2000 (0%)]\tLoss: 0.489492\n",
      "Epoch: 16 [200/2000 (10%)]\tLoss: 0.013332\n",
      "Epoch: 16 [400/2000 (20%)]\tLoss: 0.185195\n",
      "Epoch: 16 [600/2000 (30%)]\tLoss: 0.019942\n",
      "Epoch: 16 [800/2000 (40%)]\tLoss: 0.032265\n",
      "Epoch: 16 [1000/2000 (50%)]\tLoss: 0.848984\n",
      "Epoch: 16 [1200/2000 (60%)]\tLoss: 0.054642\n",
      "Epoch: 16 [1400/2000 (70%)]\tLoss: 0.105146\n",
      "Epoch: 16 [1600/2000 (80%)]\tLoss: 0.188889\n",
      "Epoch: 16 [1800/2000 (90%)]\tLoss: 0.491049\n",
      "Epoch: 17 [0/2000 (0%)]\tLoss: 0.037077\n",
      "Epoch: 17 [200/2000 (10%)]\tLoss: 0.002864\n",
      "Epoch: 17 [400/2000 (20%)]\tLoss: 0.014958\n",
      "Epoch: 17 [600/2000 (30%)]\tLoss: 0.237885\n",
      "Epoch: 17 [800/2000 (40%)]\tLoss: 0.749425\n",
      "Epoch: 17 [1000/2000 (50%)]\tLoss: 0.024138\n",
      "Epoch: 17 [1200/2000 (60%)]\tLoss: 0.187288\n",
      "Epoch: 17 [1400/2000 (70%)]\tLoss: 0.037939\n",
      "Epoch: 17 [1600/2000 (80%)]\tLoss: 0.389274\n",
      "Epoch: 17 [1800/2000 (90%)]\tLoss: 0.316086\n",
      "Epoch: 18 [0/2000 (0%)]\tLoss: 0.001409\n",
      "Epoch: 18 [200/2000 (10%)]\tLoss: 0.207875\n",
      "Epoch: 18 [400/2000 (20%)]\tLoss: 0.157994\n",
      "Epoch: 18 [600/2000 (30%)]\tLoss: 0.020572\n",
      "Epoch: 18 [800/2000 (40%)]\tLoss: 0.002873\n",
      "Epoch: 18 [1000/2000 (50%)]\tLoss: 0.007925\n",
      "Epoch: 18 [1200/2000 (60%)]\tLoss: 0.413529\n",
      "Epoch: 18 [1400/2000 (70%)]\tLoss: 0.206015\n",
      "Epoch: 18 [1600/2000 (80%)]\tLoss: 0.155441\n",
      "Epoch: 18 [1800/2000 (90%)]\tLoss: 0.228279\n",
      "Epoch: 19 [0/2000 (0%)]\tLoss: 0.026015\n",
      "Epoch: 19 [200/2000 (10%)]\tLoss: 0.031212\n",
      "Epoch: 19 [400/2000 (20%)]\tLoss: 0.293711\n",
      "Epoch: 19 [600/2000 (30%)]\tLoss: 0.010572\n",
      "Epoch: 19 [800/2000 (40%)]\tLoss: 0.069626\n",
      "Epoch: 19 [1000/2000 (50%)]\tLoss: 0.417814\n",
      "Epoch: 19 [1200/2000 (60%)]\tLoss: 0.023940\n",
      "Epoch: 19 [1400/2000 (70%)]\tLoss: 0.001120\n",
      "Epoch: 19 [1600/2000 (80%)]\tLoss: 0.125348\n",
      "Epoch: 19 [1800/2000 (90%)]\tLoss: 0.388592\n",
      "Epoch: 20 [0/2000 (0%)]\tLoss: 0.524025\n",
      "Epoch: 20 [200/2000 (10%)]\tLoss: 0.052690\n",
      "Epoch: 20 [400/2000 (20%)]\tLoss: 0.060931\n",
      "Epoch: 20 [600/2000 (30%)]\tLoss: 0.681073\n",
      "Epoch: 20 [800/2000 (40%)]\tLoss: 0.001490\n",
      "Epoch: 20 [1000/2000 (50%)]\tLoss: 0.163767\n",
      "Epoch: 20 [1200/2000 (60%)]\tLoss: 0.405390\n",
      "Epoch: 20 [1400/2000 (70%)]\tLoss: 0.019781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 [1600/2000 (80%)]\tLoss: 0.630459\n",
      "Epoch: 20 [1800/2000 (90%)]\tLoss: 0.310293\n",
      "Epoch: 21 [0/2000 (0%)]\tLoss: 0.004555\n",
      "Epoch: 21 [200/2000 (10%)]\tLoss: 0.033740\n",
      "Epoch: 21 [400/2000 (20%)]\tLoss: 0.000157\n",
      "Epoch: 21 [600/2000 (30%)]\tLoss: 0.017312\n",
      "Epoch: 21 [800/2000 (40%)]\tLoss: 0.095727\n",
      "Epoch: 21 [1000/2000 (50%)]\tLoss: 0.016831\n",
      "Epoch: 21 [1200/2000 (60%)]\tLoss: 0.108910\n",
      "Epoch: 21 [1400/2000 (70%)]\tLoss: 0.029227\n",
      "Epoch: 21 [1600/2000 (80%)]\tLoss: 0.004114\n",
      "Epoch: 21 [1800/2000 (90%)]\tLoss: 0.043560\n",
      "Epoch: 22 [0/2000 (0%)]\tLoss: 0.162118\n",
      "Epoch: 22 [200/2000 (10%)]\tLoss: 0.543471\n",
      "Epoch: 22 [400/2000 (20%)]\tLoss: 0.261112\n",
      "Epoch: 22 [600/2000 (30%)]\tLoss: 0.170364\n",
      "Epoch: 22 [800/2000 (40%)]\tLoss: 0.067468\n",
      "Epoch: 22 [1000/2000 (50%)]\tLoss: 0.118763\n",
      "Epoch: 22 [1200/2000 (60%)]\tLoss: 0.012867\n",
      "Epoch: 22 [1400/2000 (70%)]\tLoss: 0.007751\n",
      "Epoch: 22 [1600/2000 (80%)]\tLoss: 0.007162\n",
      "Epoch: 22 [1800/2000 (90%)]\tLoss: 0.006162\n",
      "Epoch: 23 [0/2000 (0%)]\tLoss: 0.001961\n",
      "Epoch: 23 [200/2000 (10%)]\tLoss: 0.021612\n",
      "Epoch: 23 [400/2000 (20%)]\tLoss: 0.111222\n",
      "Epoch: 23 [600/2000 (30%)]\tLoss: 0.001593\n",
      "Epoch: 23 [800/2000 (40%)]\tLoss: 0.038358\n",
      "Epoch: 23 [1000/2000 (50%)]\tLoss: 0.006840\n",
      "Epoch: 23 [1200/2000 (60%)]\tLoss: 0.003138\n",
      "Epoch: 23 [1400/2000 (70%)]\tLoss: 0.276905\n",
      "Epoch: 23 [1600/2000 (80%)]\tLoss: 0.024818\n",
      "Epoch: 23 [1800/2000 (90%)]\tLoss: 0.117612\n",
      "Epoch: 24 [0/2000 (0%)]\tLoss: 0.008200\n",
      "Epoch: 24 [200/2000 (10%)]\tLoss: 0.003189\n",
      "Epoch: 24 [400/2000 (20%)]\tLoss: 0.006277\n",
      "Epoch: 24 [600/2000 (30%)]\tLoss: 0.327490\n",
      "Epoch: 24 [800/2000 (40%)]\tLoss: 0.000141\n",
      "Epoch: 24 [1000/2000 (50%)]\tLoss: 1.753090\n",
      "Epoch: 24 [1200/2000 (60%)]\tLoss: 0.048287\n",
      "Epoch: 24 [1400/2000 (70%)]\tLoss: 0.633584\n",
      "Epoch: 24 [1600/2000 (80%)]\tLoss: 0.001513\n",
      "Epoch: 24 [1800/2000 (90%)]\tLoss: 0.006597\n",
      "Epoch: 25 [0/2000 (0%)]\tLoss: 0.015469\n",
      "Epoch: 25 [200/2000 (10%)]\tLoss: 0.001255\n",
      "Epoch: 25 [400/2000 (20%)]\tLoss: 0.001742\n",
      "Epoch: 25 [600/2000 (30%)]\tLoss: 0.000361\n",
      "Epoch: 25 [800/2000 (40%)]\tLoss: 0.011394\n",
      "Epoch: 25 [1000/2000 (50%)]\tLoss: 0.089351\n",
      "Epoch: 25 [1200/2000 (60%)]\tLoss: 0.000333\n",
      "Epoch: 25 [1400/2000 (70%)]\tLoss: 0.003126\n",
      "Epoch: 25 [1600/2000 (80%)]\tLoss: 0.006941\n",
      "Epoch: 25 [1800/2000 (90%)]\tLoss: 0.122173\n",
      "Epoch: 26 [0/2000 (0%)]\tLoss: 0.000854\n",
      "Epoch: 26 [200/2000 (10%)]\tLoss: 0.120770\n",
      "Epoch: 26 [400/2000 (20%)]\tLoss: 0.000153\n",
      "Epoch: 26 [600/2000 (30%)]\tLoss: 0.170338\n",
      "Epoch: 26 [800/2000 (40%)]\tLoss: 0.316297\n",
      "Epoch: 26 [1000/2000 (50%)]\tLoss: 0.009799\n",
      "Epoch: 26 [1200/2000 (60%)]\tLoss: 0.001121\n",
      "Epoch: 26 [1400/2000 (70%)]\tLoss: 0.000926\n",
      "Epoch: 26 [1600/2000 (80%)]\tLoss: 0.030374\n",
      "Epoch: 26 [1800/2000 (90%)]\tLoss: 0.343634\n",
      "Epoch: 27 [0/2000 (0%)]\tLoss: 0.037065\n",
      "Epoch: 27 [200/2000 (10%)]\tLoss: 0.023253\n",
      "Epoch: 27 [400/2000 (20%)]\tLoss: 0.336502\n",
      "Epoch: 27 [600/2000 (30%)]\tLoss: 0.005796\n",
      "Epoch: 27 [800/2000 (40%)]\tLoss: 0.237793\n",
      "Epoch: 27 [1000/2000 (50%)]\tLoss: 0.000924\n",
      "Epoch: 27 [1200/2000 (60%)]\tLoss: 0.012245\n",
      "Epoch: 27 [1400/2000 (70%)]\tLoss: 0.003280\n",
      "Epoch: 27 [1600/2000 (80%)]\tLoss: 0.000196\n",
      "Epoch: 27 [1800/2000 (90%)]\tLoss: 0.007068\n",
      "Epoch: 28 [0/2000 (0%)]\tLoss: 0.277789\n",
      "Epoch: 28 [200/2000 (10%)]\tLoss: 0.012801\n",
      "Epoch: 28 [400/2000 (20%)]\tLoss: 0.000493\n",
      "Epoch: 28 [600/2000 (30%)]\tLoss: 0.695028\n",
      "Epoch: 28 [800/2000 (40%)]\tLoss: 0.002476\n",
      "Epoch: 28 [1000/2000 (50%)]\tLoss: 0.073436\n",
      "Epoch: 28 [1200/2000 (60%)]\tLoss: 1.050699\n",
      "Epoch: 28 [1400/2000 (70%)]\tLoss: 0.099178\n",
      "Epoch: 28 [1600/2000 (80%)]\tLoss: 0.002768\n",
      "Epoch: 28 [1800/2000 (90%)]\tLoss: 0.000491\n",
      "Epoch: 29 [0/2000 (0%)]\tLoss: 0.327917\n",
      "Epoch: 29 [200/2000 (10%)]\tLoss: 0.000374\n",
      "Epoch: 29 [400/2000 (20%)]\tLoss: 0.000289\n",
      "Epoch: 29 [600/2000 (30%)]\tLoss: 0.001534\n",
      "Epoch: 29 [800/2000 (40%)]\tLoss: 0.009596\n",
      "Epoch: 29 [1000/2000 (50%)]\tLoss: 0.012651\n",
      "Epoch: 29 [1200/2000 (60%)]\tLoss: 0.370522\n",
      "Epoch: 29 [1400/2000 (70%)]\tLoss: 0.003109\n",
      "Epoch: 29 [1600/2000 (80%)]\tLoss: 0.036226\n",
      "Epoch: 29 [1800/2000 (90%)]\tLoss: 0.000248\n",
      "Epoch: 30 [0/2000 (0%)]\tLoss: 0.026534\n",
      "Epoch: 30 [200/2000 (10%)]\tLoss: 0.000208\n",
      "Epoch: 30 [400/2000 (20%)]\tLoss: 0.146549\n",
      "Epoch: 30 [600/2000 (30%)]\tLoss: 0.018597\n",
      "Epoch: 30 [800/2000 (40%)]\tLoss: 1.065814\n",
      "Epoch: 30 [1000/2000 (50%)]\tLoss: 0.000247\n",
      "Epoch: 30 [1200/2000 (60%)]\tLoss: 0.143721\n",
      "Epoch: 30 [1400/2000 (70%)]\tLoss: 0.011090\n",
      "Epoch: 30 [1600/2000 (80%)]\tLoss: 0.000247\n",
      "Epoch: 30 [1800/2000 (90%)]\tLoss: 0.004435\n",
      "Epoch: 31 [0/2000 (0%)]\tLoss: 0.000414\n",
      "Epoch: 31 [200/2000 (10%)]\tLoss: 0.000455\n",
      "Epoch: 31 [400/2000 (20%)]\tLoss: 0.003940\n",
      "Epoch: 31 [600/2000 (30%)]\tLoss: 0.008537\n",
      "Epoch: 31 [800/2000 (40%)]\tLoss: 0.120689\n",
      "Epoch: 31 [1000/2000 (50%)]\tLoss: 0.016680\n",
      "Epoch: 31 [1200/2000 (60%)]\tLoss: 0.030412\n",
      "Epoch: 31 [1400/2000 (70%)]\tLoss: 0.001959\n",
      "Epoch: 31 [1600/2000 (80%)]\tLoss: 0.352350\n",
      "Epoch: 31 [1800/2000 (90%)]\tLoss: 0.005477\n",
      "Epoch: 32 [0/2000 (0%)]\tLoss: 0.001268\n",
      "Epoch: 32 [200/2000 (10%)]\tLoss: 0.032703\n",
      "Epoch: 32 [400/2000 (20%)]\tLoss: 0.005223\n",
      "Epoch: 32 [600/2000 (30%)]\tLoss: 0.009469\n",
      "Epoch: 32 [800/2000 (40%)]\tLoss: 0.001595\n",
      "Epoch: 32 [1000/2000 (50%)]\tLoss: 1.489559\n",
      "Epoch: 32 [1200/2000 (60%)]\tLoss: 0.391262\n",
      "Epoch: 32 [1400/2000 (70%)]\tLoss: 0.001803\n",
      "Epoch: 32 [1600/2000 (80%)]\tLoss: 0.010843\n",
      "Epoch: 32 [1800/2000 (90%)]\tLoss: 0.001567\n",
      "Epoch: 33 [0/2000 (0%)]\tLoss: 0.000553\n",
      "Epoch: 33 [200/2000 (10%)]\tLoss: 0.000189\n",
      "Epoch: 33 [400/2000 (20%)]\tLoss: 0.030975\n",
      "Epoch: 33 [600/2000 (30%)]\tLoss: 0.001579\n",
      "Epoch: 33 [800/2000 (40%)]\tLoss: 0.053863\n",
      "Epoch: 33 [1000/2000 (50%)]\tLoss: 0.008253\n",
      "Epoch: 33 [1200/2000 (60%)]\tLoss: 1.463406\n",
      "Epoch: 33 [1400/2000 (70%)]\tLoss: 0.209300\n",
      "Epoch: 33 [1600/2000 (80%)]\tLoss: 0.110306\n",
      "Epoch: 33 [1800/2000 (90%)]\tLoss: 0.000035\n",
      "Epoch: 34 [0/2000 (0%)]\tLoss: 0.000465\n",
      "Epoch: 34 [200/2000 (10%)]\tLoss: 0.000058\n",
      "Epoch: 34 [400/2000 (20%)]\tLoss: 0.006639\n",
      "Epoch: 34 [600/2000 (30%)]\tLoss: 0.032158\n",
      "Epoch: 34 [800/2000 (40%)]\tLoss: 0.158545\n",
      "Epoch: 34 [1000/2000 (50%)]\tLoss: 0.000109\n",
      "Epoch: 34 [1200/2000 (60%)]\tLoss: 0.034812\n",
      "Epoch: 34 [1400/2000 (70%)]\tLoss: 0.005211\n",
      "Epoch: 34 [1600/2000 (80%)]\tLoss: 0.001261\n",
      "Epoch: 34 [1800/2000 (90%)]\tLoss: 0.030715\n",
      "Epoch: 35 [0/2000 (0%)]\tLoss: 0.000622\n",
      "Epoch: 35 [200/2000 (10%)]\tLoss: 0.000189\n",
      "Epoch: 35 [400/2000 (20%)]\tLoss: 0.004077\n",
      "Epoch: 35 [600/2000 (30%)]\tLoss: 0.002879\n",
      "Epoch: 35 [800/2000 (40%)]\tLoss: 0.050399\n",
      "Epoch: 35 [1000/2000 (50%)]\tLoss: 0.005396\n",
      "Epoch: 35 [1200/2000 (60%)]\tLoss: 0.509419\n",
      "Epoch: 35 [1400/2000 (70%)]\tLoss: 0.001498\n",
      "Epoch: 35 [1600/2000 (80%)]\tLoss: 0.000830\n",
      "Epoch: 35 [1800/2000 (90%)]\tLoss: 0.112891\n",
      "Epoch: 36 [0/2000 (0%)]\tLoss: 0.001639\n",
      "Epoch: 36 [200/2000 (10%)]\tLoss: 0.000518\n",
      "Epoch: 36 [400/2000 (20%)]\tLoss: 0.002302\n",
      "Epoch: 36 [600/2000 (30%)]\tLoss: 0.002097\n",
      "Epoch: 36 [800/2000 (40%)]\tLoss: 0.005780\n",
      "Epoch: 36 [1000/2000 (50%)]\tLoss: 0.000037\n",
      "Epoch: 36 [1200/2000 (60%)]\tLoss: 0.001089\n",
      "Epoch: 36 [1400/2000 (70%)]\tLoss: 0.016226\n",
      "Epoch: 36 [1600/2000 (80%)]\tLoss: 0.002895\n",
      "Epoch: 36 [1800/2000 (90%)]\tLoss: 0.003211\n",
      "Epoch: 37 [0/2000 (0%)]\tLoss: 0.000225\n",
      "Epoch: 37 [200/2000 (10%)]\tLoss: 0.000977\n",
      "Epoch: 37 [400/2000 (20%)]\tLoss: 0.000811\n",
      "Epoch: 37 [600/2000 (30%)]\tLoss: 0.001013\n",
      "Epoch: 37 [800/2000 (40%)]\tLoss: 0.000229\n",
      "Epoch: 37 [1000/2000 (50%)]\tLoss: 0.001448\n",
      "Epoch: 37 [1200/2000 (60%)]\tLoss: 0.000212\n",
      "Epoch: 37 [1400/2000 (70%)]\tLoss: 0.000107\n",
      "Epoch: 37 [1600/2000 (80%)]\tLoss: 0.000053\n",
      "Epoch: 37 [1800/2000 (90%)]\tLoss: 0.000429\n",
      "Epoch: 38 [0/2000 (0%)]\tLoss: 0.000173\n",
      "Epoch: 38 [200/2000 (10%)]\tLoss: 0.000374\n",
      "Epoch: 38 [400/2000 (20%)]\tLoss: 0.002571\n",
      "Epoch: 38 [600/2000 (30%)]\tLoss: 0.000784\n",
      "Epoch: 38 [800/2000 (40%)]\tLoss: 0.002888\n",
      "Epoch: 38 [1000/2000 (50%)]\tLoss: 0.000038\n",
      "Epoch: 38 [1200/2000 (60%)]\tLoss: 0.000386\n",
      "Epoch: 38 [1400/2000 (70%)]\tLoss: 0.007473\n",
      "Epoch: 38 [1600/2000 (80%)]\tLoss: 0.179385\n",
      "Epoch: 38 [1800/2000 (90%)]\tLoss: 0.335869\n",
      "Epoch: 39 [0/2000 (0%)]\tLoss: 0.000924\n",
      "Epoch: 39 [200/2000 (10%)]\tLoss: 0.000530\n",
      "Epoch: 39 [400/2000 (20%)]\tLoss: 0.008871\n",
      "Epoch: 39 [600/2000 (30%)]\tLoss: 0.031973\n",
      "Epoch: 39 [800/2000 (40%)]\tLoss: 0.001148\n",
      "Epoch: 39 [1000/2000 (50%)]\tLoss: 0.041806\n",
      "Epoch: 39 [1200/2000 (60%)]\tLoss: 0.013811\n",
      "Epoch: 39 [1400/2000 (70%)]\tLoss: 0.000011\n",
      "Epoch: 39 [1600/2000 (80%)]\tLoss: 0.025474\n",
      "Epoch: 39 [1800/2000 (90%)]\tLoss: 0.000189\n",
      "Epoch: 40 [0/2000 (0%)]\tLoss: 0.000942\n",
      "Epoch: 40 [200/2000 (10%)]\tLoss: 0.004184\n",
      "Epoch: 40 [400/2000 (20%)]\tLoss: 0.000790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 [600/2000 (30%)]\tLoss: 0.001077\n",
      "Epoch: 40 [800/2000 (40%)]\tLoss: 0.002099\n",
      "Epoch: 40 [1000/2000 (50%)]\tLoss: 0.003767\n",
      "Epoch: 40 [1200/2000 (60%)]\tLoss: 0.000171\n",
      "Epoch: 40 [1400/2000 (70%)]\tLoss: 0.001339\n",
      "Epoch: 40 [1600/2000 (80%)]\tLoss: 0.000316\n",
      "Epoch: 40 [1800/2000 (90%)]\tLoss: 0.002192\n",
      "Epoch: 41 [0/2000 (0%)]\tLoss: 0.000681\n",
      "Epoch: 41 [200/2000 (10%)]\tLoss: 0.000873\n",
      "Epoch: 41 [400/2000 (20%)]\tLoss: 0.002975\n",
      "Epoch: 41 [600/2000 (30%)]\tLoss: 0.002112\n",
      "Epoch: 41 [800/2000 (40%)]\tLoss: 0.000653\n",
      "Epoch: 41 [1000/2000 (50%)]\tLoss: 0.000048\n",
      "Epoch: 41 [1200/2000 (60%)]\tLoss: 0.000119\n",
      "Epoch: 41 [1400/2000 (70%)]\tLoss: 0.000177\n",
      "Epoch: 41 [1600/2000 (80%)]\tLoss: 0.000223\n",
      "Epoch: 41 [1800/2000 (90%)]\tLoss: 0.000169\n",
      "Epoch: 42 [0/2000 (0%)]\tLoss: 0.000381\n",
      "Epoch: 42 [200/2000 (10%)]\tLoss: 0.000830\n",
      "Epoch: 42 [400/2000 (20%)]\tLoss: 0.000081\n",
      "Epoch: 42 [600/2000 (30%)]\tLoss: 0.000031\n",
      "Epoch: 42 [800/2000 (40%)]\tLoss: 0.000075\n",
      "Epoch: 42 [1000/2000 (50%)]\tLoss: 0.000172\n",
      "Epoch: 42 [1200/2000 (60%)]\tLoss: 0.000112\n",
      "Epoch: 42 [1400/2000 (70%)]\tLoss: 0.000026\n",
      "Epoch: 42 [1600/2000 (80%)]\tLoss: 0.000072\n",
      "Epoch: 42 [1800/2000 (90%)]\tLoss: 0.000406\n",
      "Epoch: 43 [0/2000 (0%)]\tLoss: 0.000028\n",
      "Epoch: 43 [200/2000 (10%)]\tLoss: 0.000692\n",
      "Epoch: 43 [400/2000 (20%)]\tLoss: 0.000004\n",
      "Epoch: 43 [600/2000 (30%)]\tLoss: 0.000298\n",
      "Epoch: 43 [800/2000 (40%)]\tLoss: 0.000074\n",
      "Epoch: 43 [1000/2000 (50%)]\tLoss: 0.000068\n",
      "Epoch: 43 [1200/2000 (60%)]\tLoss: 0.000008\n",
      "Epoch: 43 [1400/2000 (70%)]\tLoss: 0.002354\n",
      "Epoch: 43 [1600/2000 (80%)]\tLoss: 0.000888\n",
      "Epoch: 43 [1800/2000 (90%)]\tLoss: 0.000103\n",
      "Epoch: 44 [0/2000 (0%)]\tLoss: 0.000034\n",
      "Epoch: 44 [200/2000 (10%)]\tLoss: 0.000003\n",
      "Epoch: 44 [400/2000 (20%)]\tLoss: 0.000311\n",
      "Epoch: 44 [600/2000 (30%)]\tLoss: 0.000055\n",
      "Epoch: 44 [800/2000 (40%)]\tLoss: 0.000077\n",
      "Epoch: 44 [1000/2000 (50%)]\tLoss: 0.000078\n",
      "Epoch: 44 [1200/2000 (60%)]\tLoss: 0.000910\n",
      "Epoch: 44 [1400/2000 (70%)]\tLoss: 0.000312\n",
      "Epoch: 44 [1600/2000 (80%)]\tLoss: 0.000018\n",
      "Epoch: 44 [1800/2000 (90%)]\tLoss: 0.000788\n",
      "Epoch: 45 [0/2000 (0%)]\tLoss: 0.000725\n",
      "Epoch: 45 [200/2000 (10%)]\tLoss: 0.000348\n",
      "Epoch: 45 [400/2000 (20%)]\tLoss: 0.000114\n",
      "Epoch: 45 [600/2000 (30%)]\tLoss: 0.000080\n",
      "Epoch: 45 [800/2000 (40%)]\tLoss: 0.000164\n",
      "Epoch: 45 [1000/2000 (50%)]\tLoss: 0.000131\n",
      "Epoch: 45 [1200/2000 (60%)]\tLoss: 0.000094\n",
      "Epoch: 45 [1400/2000 (70%)]\tLoss: 0.000046\n",
      "Epoch: 45 [1600/2000 (80%)]\tLoss: 0.000518\n",
      "Epoch: 45 [1800/2000 (90%)]\tLoss: 0.000061\n",
      "Epoch: 46 [0/2000 (0%)]\tLoss: 0.000503\n",
      "Epoch: 46 [200/2000 (10%)]\tLoss: 0.000085\n",
      "Epoch: 46 [400/2000 (20%)]\tLoss: 0.000007\n",
      "Epoch: 46 [600/2000 (30%)]\tLoss: 0.000212\n",
      "Epoch: 46 [800/2000 (40%)]\tLoss: 0.000071\n",
      "Epoch: 46 [1000/2000 (50%)]\tLoss: 0.000032\n",
      "Epoch: 46 [1200/2000 (60%)]\tLoss: 0.000049\n",
      "Epoch: 46 [1400/2000 (70%)]\tLoss: 0.000215\n",
      "Epoch: 46 [1600/2000 (80%)]\tLoss: 0.000142\n",
      "Epoch: 46 [1800/2000 (90%)]\tLoss: 0.000025\n",
      "Epoch: 47 [0/2000 (0%)]\tLoss: 0.000249\n",
      "Epoch: 47 [200/2000 (10%)]\tLoss: 0.000040\n",
      "Epoch: 47 [400/2000 (20%)]\tLoss: 0.000024\n",
      "Epoch: 47 [600/2000 (30%)]\tLoss: 0.000118\n",
      "Epoch: 47 [800/2000 (40%)]\tLoss: 0.000500\n",
      "Epoch: 47 [1000/2000 (50%)]\tLoss: 0.000140\n",
      "Epoch: 47 [1200/2000 (60%)]\tLoss: 0.000186\n",
      "Epoch: 47 [1400/2000 (70%)]\tLoss: 0.000076\n",
      "Epoch: 47 [1600/2000 (80%)]\tLoss: 0.000124\n",
      "Epoch: 47 [1800/2000 (90%)]\tLoss: 0.000032\n",
      "Epoch: 48 [0/2000 (0%)]\tLoss: 0.000095\n",
      "Epoch: 48 [200/2000 (10%)]\tLoss: 0.000022\n",
      "Epoch: 48 [400/2000 (20%)]\tLoss: 0.000014\n",
      "Epoch: 48 [600/2000 (30%)]\tLoss: 0.000401\n",
      "Epoch: 48 [800/2000 (40%)]\tLoss: 0.000299\n",
      "Epoch: 48 [1000/2000 (50%)]\tLoss: 0.000225\n",
      "Epoch: 48 [1200/2000 (60%)]\tLoss: 0.000168\n",
      "Epoch: 48 [1400/2000 (70%)]\tLoss: 0.000064\n",
      "Epoch: 48 [1600/2000 (80%)]\tLoss: 0.000009\n",
      "Epoch: 48 [1800/2000 (90%)]\tLoss: 0.000378\n",
      "Epoch: 49 [0/2000 (0%)]\tLoss: 0.000229\n",
      "Epoch: 49 [200/2000 (10%)]\tLoss: 0.000020\n",
      "Epoch: 49 [400/2000 (20%)]\tLoss: 0.000085\n",
      "Epoch: 49 [600/2000 (30%)]\tLoss: 0.000005\n",
      "Epoch: 49 [800/2000 (40%)]\tLoss: 0.000063\n",
      "Epoch: 49 [1000/2000 (50%)]\tLoss: 0.000014\n",
      "Epoch: 49 [1200/2000 (60%)]\tLoss: 0.000079\n",
      "Epoch: 49 [1400/2000 (70%)]\tLoss: 0.000104\n",
      "Epoch: 49 [1600/2000 (80%)]\tLoss: 0.000186\n",
      "Epoch: 49 [1800/2000 (90%)]\tLoss: 0.000057\n",
      "Epoch: 50 [0/2000 (0%)]\tLoss: 0.000015\n",
      "Epoch: 50 [200/2000 (10%)]\tLoss: 0.000001\n",
      "Epoch: 50 [400/2000 (20%)]\tLoss: 0.000036\n",
      "Epoch: 50 [600/2000 (30%)]\tLoss: 0.000652\n",
      "Epoch: 50 [800/2000 (40%)]\tLoss: 0.000009\n",
      "Epoch: 50 [1000/2000 (50%)]\tLoss: 0.000958\n",
      "Epoch: 50 [1200/2000 (60%)]\tLoss: 0.000020\n",
      "Epoch: 50 [1400/2000 (70%)]\tLoss: 0.000126\n",
      "Epoch: 50 [1600/2000 (80%)]\tLoss: 0.000036\n",
      "Epoch: 50 [1800/2000 (90%)]\tLoss: 0.000353\n",
      "Finished training in  593.338 seconds \n",
      "\n",
      "Test set: Average loss: 0.2589, Accuracy: 68/100 (68%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa8c11d550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "#Import\n",
    "data_transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "train_set = datasets.ImageFolder(root='clouds_medium',\n",
    "                                transform=data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=1)\n",
    "\n",
    "test_set = datasets.ImageFolder(root='clouds_medium_test',\n",
    "                                transform=data_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                             batch_size=4,shuffle=False,\n",
    "                                             num_workers=1)\n",
    "\n",
    "cloud_classes = ('0', 'pi/4', 'pi/2', '3pi/4')\n",
    "\n",
    "#Model\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(32 * 32, 200)\n",
    "            self.fc2 = nn.Linear(200, 200)\n",
    "            self.fc3 = nn.Linear(200, 4)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return F.log_softmax(input=x)\n",
    "model = Net()\n",
    "\n",
    "#Optimizer\n",
    "import torch.optim as optim\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#Training\n",
    "import time\n",
    "start_time = time.time()\n",
    "print(\"Started training\")\n",
    "\n",
    "epochs = 50\n",
    "print_interval = 50\n",
    "tempo = []\n",
    "acc = []\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    for batch_idx, (data, target) in enumerate(train_loader): \n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        data = data.view(-1, 32*32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        net_out = model(data)\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % print_interval == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "    tempo.append(epoch)\n",
    "    acc.append(loss.data[0])\n",
    "    \n",
    "print(\"Finished training in  %.3f seconds \" % (time.time() - start_time))\n",
    "\n",
    "#Testing\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    \n",
    "    data = data.view(-1, 32 * 32)\n",
    "    net_out = model(data)\n",
    "    \n",
    "    test_loss += criterion(net_out, target).data[0]\n",
    "    pred = net_out.data.max(1)[1]\n",
    "    correct += pred.eq(target.data).sum() \n",
    "\n",
    "test_loss /= len(test_loader.dataset) \n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "#Saving\n",
    "torch.save(model.state_dict(), \"MODEL_trainMEDIUM_pytorchMCV2\")\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tempo, acc)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss variation - Medium training')\n",
    "plt.savefig('Loss_medtraining.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et pour terminer avec le dur, précision de 45% :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n",
      "Epoch: 1 [0/2000 (0%)]\tLoss: 1.394337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [200/2000 (10%)]\tLoss: 1.403620\n",
      "Epoch: 1 [400/2000 (20%)]\tLoss: 1.489994\n",
      "Epoch: 1 [600/2000 (30%)]\tLoss: 1.381952\n",
      "Epoch: 1 [800/2000 (40%)]\tLoss: 1.343594\n",
      "Epoch: 1 [1000/2000 (50%)]\tLoss: 1.458528\n",
      "Epoch: 1 [1200/2000 (60%)]\tLoss: 1.420861\n",
      "Epoch: 1 [1400/2000 (70%)]\tLoss: 1.380307\n",
      "Epoch: 1 [1600/2000 (80%)]\tLoss: 1.419491\n",
      "Epoch: 1 [1800/2000 (90%)]\tLoss: 1.414714\n",
      "Epoch: 2 [0/2000 (0%)]\tLoss: 1.396639\n",
      "Epoch: 2 [200/2000 (10%)]\tLoss: 1.331998\n",
      "Epoch: 2 [400/2000 (20%)]\tLoss: 1.375875\n",
      "Epoch: 2 [600/2000 (30%)]\tLoss: 1.352540\n",
      "Epoch: 2 [800/2000 (40%)]\tLoss: 1.354452\n",
      "Epoch: 2 [1000/2000 (50%)]\tLoss: 1.447686\n",
      "Epoch: 2 [1200/2000 (60%)]\tLoss: 1.437636\n",
      "Epoch: 2 [1400/2000 (70%)]\tLoss: 1.347588\n",
      "Epoch: 2 [1600/2000 (80%)]\tLoss: 1.323403\n",
      "Epoch: 2 [1800/2000 (90%)]\tLoss: 1.399114\n",
      "Epoch: 3 [0/2000 (0%)]\tLoss: 1.284377\n",
      "Epoch: 3 [200/2000 (10%)]\tLoss: 1.388207\n",
      "Epoch: 3 [400/2000 (20%)]\tLoss: 1.395785\n",
      "Epoch: 3 [600/2000 (30%)]\tLoss: 1.378447\n",
      "Epoch: 3 [800/2000 (40%)]\tLoss: 1.382730\n",
      "Epoch: 3 [1000/2000 (50%)]\tLoss: 1.385088\n",
      "Epoch: 3 [1200/2000 (60%)]\tLoss: 1.437826\n",
      "Epoch: 3 [1400/2000 (70%)]\tLoss: 1.408707\n",
      "Epoch: 3 [1600/2000 (80%)]\tLoss: 1.403772\n",
      "Epoch: 3 [1800/2000 (90%)]\tLoss: 1.406284\n",
      "Epoch: 4 [0/2000 (0%)]\tLoss: 1.429456\n",
      "Epoch: 4 [200/2000 (10%)]\tLoss: 1.450080\n",
      "Epoch: 4 [400/2000 (20%)]\tLoss: 1.442780\n",
      "Epoch: 4 [600/2000 (30%)]\tLoss: 1.460371\n",
      "Epoch: 4 [800/2000 (40%)]\tLoss: 1.367301\n",
      "Epoch: 4 [1000/2000 (50%)]\tLoss: 1.375770\n",
      "Epoch: 4 [1200/2000 (60%)]\tLoss: 1.403739\n",
      "Epoch: 4 [1400/2000 (70%)]\tLoss: 1.390409\n",
      "Epoch: 4 [1600/2000 (80%)]\tLoss: 1.396305\n",
      "Epoch: 4 [1800/2000 (90%)]\tLoss: 1.352662\n",
      "Epoch: 5 [0/2000 (0%)]\tLoss: 1.426340\n",
      "Epoch: 5 [200/2000 (10%)]\tLoss: 1.446877\n",
      "Epoch: 5 [400/2000 (20%)]\tLoss: 1.351891\n",
      "Epoch: 5 [600/2000 (30%)]\tLoss: 1.327929\n",
      "Epoch: 5 [800/2000 (40%)]\tLoss: 1.360398\n",
      "Epoch: 5 [1000/2000 (50%)]\tLoss: 1.357845\n",
      "Epoch: 5 [1200/2000 (60%)]\tLoss: 1.340227\n",
      "Epoch: 5 [1400/2000 (70%)]\tLoss: 1.325752\n",
      "Epoch: 5 [1600/2000 (80%)]\tLoss: 1.330183\n",
      "Epoch: 5 [1800/2000 (90%)]\tLoss: 1.432787\n",
      "Epoch: 6 [0/2000 (0%)]\tLoss: 1.345964\n",
      "Epoch: 6 [200/2000 (10%)]\tLoss: 1.360105\n",
      "Epoch: 6 [400/2000 (20%)]\tLoss: 1.469810\n",
      "Epoch: 6 [600/2000 (30%)]\tLoss: 1.428501\n",
      "Epoch: 6 [800/2000 (40%)]\tLoss: 1.369798\n",
      "Epoch: 6 [1000/2000 (50%)]\tLoss: 1.409027\n",
      "Epoch: 6 [1200/2000 (60%)]\tLoss: 1.305651\n",
      "Epoch: 6 [1400/2000 (70%)]\tLoss: 1.478503\n",
      "Epoch: 6 [1600/2000 (80%)]\tLoss: 1.488718\n",
      "Epoch: 6 [1800/2000 (90%)]\tLoss: 1.424384\n",
      "Epoch: 7 [0/2000 (0%)]\tLoss: 1.251206\n",
      "Epoch: 7 [200/2000 (10%)]\tLoss: 1.396867\n",
      "Epoch: 7 [400/2000 (20%)]\tLoss: 1.436492\n",
      "Epoch: 7 [600/2000 (30%)]\tLoss: 1.286778\n",
      "Epoch: 7 [800/2000 (40%)]\tLoss: 1.342500\n",
      "Epoch: 7 [1000/2000 (50%)]\tLoss: 1.333285\n",
      "Epoch: 7 [1200/2000 (60%)]\tLoss: 1.408619\n",
      "Epoch: 7 [1400/2000 (70%)]\tLoss: 1.339108\n",
      "Epoch: 7 [1600/2000 (80%)]\tLoss: 1.506685\n",
      "Epoch: 7 [1800/2000 (90%)]\tLoss: 1.524694\n",
      "Epoch: 8 [0/2000 (0%)]\tLoss: 1.414437\n",
      "Epoch: 8 [200/2000 (10%)]\tLoss: 1.276248\n",
      "Epoch: 8 [400/2000 (20%)]\tLoss: 1.323570\n",
      "Epoch: 8 [600/2000 (30%)]\tLoss: 1.221639\n",
      "Epoch: 8 [800/2000 (40%)]\tLoss: 1.277869\n",
      "Epoch: 8 [1000/2000 (50%)]\tLoss: 1.197239\n",
      "Epoch: 8 [1200/2000 (60%)]\tLoss: 1.448001\n",
      "Epoch: 8 [1400/2000 (70%)]\tLoss: 1.285826\n",
      "Epoch: 8 [1600/2000 (80%)]\tLoss: 1.283321\n",
      "Epoch: 8 [1800/2000 (90%)]\tLoss: 1.658902\n",
      "Epoch: 9 [0/2000 (0%)]\tLoss: 1.296094\n",
      "Epoch: 9 [200/2000 (10%)]\tLoss: 1.635148\n",
      "Epoch: 9 [400/2000 (20%)]\tLoss: 1.177994\n",
      "Epoch: 9 [600/2000 (30%)]\tLoss: 1.380072\n",
      "Epoch: 9 [800/2000 (40%)]\tLoss: 1.744009\n",
      "Epoch: 9 [1000/2000 (50%)]\tLoss: 1.352273\n",
      "Epoch: 9 [1200/2000 (60%)]\tLoss: 1.658895\n",
      "Epoch: 9 [1400/2000 (70%)]\tLoss: 1.168489\n",
      "Epoch: 9 [1600/2000 (80%)]\tLoss: 1.235915\n",
      "Epoch: 9 [1800/2000 (90%)]\tLoss: 1.246397\n",
      "Epoch: 10 [0/2000 (0%)]\tLoss: 1.018561\n",
      "Epoch: 10 [200/2000 (10%)]\tLoss: 1.029881\n",
      "Epoch: 10 [400/2000 (20%)]\tLoss: 0.842669\n",
      "Epoch: 10 [600/2000 (30%)]\tLoss: 0.840011\n",
      "Epoch: 10 [800/2000 (40%)]\tLoss: 0.998420\n",
      "Epoch: 10 [1000/2000 (50%)]\tLoss: 1.122038\n",
      "Epoch: 10 [1200/2000 (60%)]\tLoss: 1.039286\n",
      "Epoch: 10 [1400/2000 (70%)]\tLoss: 0.979201\n",
      "Epoch: 10 [1600/2000 (80%)]\tLoss: 1.060208\n",
      "Epoch: 10 [1800/2000 (90%)]\tLoss: 1.359185\n",
      "Epoch: 11 [0/2000 (0%)]\tLoss: 1.184206\n",
      "Epoch: 11 [200/2000 (10%)]\tLoss: 1.470423\n",
      "Epoch: 11 [400/2000 (20%)]\tLoss: 1.572734\n",
      "Epoch: 11 [600/2000 (30%)]\tLoss: 0.892127\n",
      "Epoch: 11 [800/2000 (40%)]\tLoss: 1.422470\n",
      "Epoch: 11 [1000/2000 (50%)]\tLoss: 1.365778\n",
      "Epoch: 11 [1200/2000 (60%)]\tLoss: 1.167264\n",
      "Epoch: 11 [1400/2000 (70%)]\tLoss: 0.920263\n",
      "Epoch: 11 [1600/2000 (80%)]\tLoss: 0.999255\n",
      "Epoch: 11 [1800/2000 (90%)]\tLoss: 0.962386\n",
      "Epoch: 12 [0/2000 (0%)]\tLoss: 1.442185\n",
      "Epoch: 12 [200/2000 (10%)]\tLoss: 1.202196\n",
      "Epoch: 12 [400/2000 (20%)]\tLoss: 0.919738\n",
      "Epoch: 12 [600/2000 (30%)]\tLoss: 0.848745\n",
      "Epoch: 12 [800/2000 (40%)]\tLoss: 0.851843\n",
      "Epoch: 12 [1000/2000 (50%)]\tLoss: 0.870046\n",
      "Epoch: 12 [1200/2000 (60%)]\tLoss: 1.694513\n",
      "Epoch: 12 [1400/2000 (70%)]\tLoss: 0.669449\n",
      "Epoch: 12 [1600/2000 (80%)]\tLoss: 1.225110\n",
      "Epoch: 12 [1800/2000 (90%)]\tLoss: 0.992725\n",
      "Epoch: 13 [0/2000 (0%)]\tLoss: 1.119699\n",
      "Epoch: 13 [200/2000 (10%)]\tLoss: 0.609292\n",
      "Epoch: 13 [400/2000 (20%)]\tLoss: 0.673970\n",
      "Epoch: 13 [600/2000 (30%)]\tLoss: 1.146591\n",
      "Epoch: 13 [800/2000 (40%)]\tLoss: 0.655813\n",
      "Epoch: 13 [1000/2000 (50%)]\tLoss: 0.769259\n",
      "Epoch: 13 [1200/2000 (60%)]\tLoss: 0.468489\n",
      "Epoch: 13 [1400/2000 (70%)]\tLoss: 0.948683\n",
      "Epoch: 13 [1600/2000 (80%)]\tLoss: 1.037713\n",
      "Epoch: 13 [1800/2000 (90%)]\tLoss: 1.009327\n",
      "Epoch: 14 [0/2000 (0%)]\tLoss: 0.686441\n",
      "Epoch: 14 [200/2000 (10%)]\tLoss: 0.614603\n",
      "Epoch: 14 [400/2000 (20%)]\tLoss: 1.005186\n",
      "Epoch: 14 [600/2000 (30%)]\tLoss: 1.033947\n",
      "Epoch: 14 [800/2000 (40%)]\tLoss: 0.602159\n",
      "Epoch: 14 [1000/2000 (50%)]\tLoss: 0.580214\n",
      "Epoch: 14 [1200/2000 (60%)]\tLoss: 0.755498\n",
      "Epoch: 14 [1400/2000 (70%)]\tLoss: 0.752395\n",
      "Epoch: 14 [1600/2000 (80%)]\tLoss: 0.569515\n",
      "Epoch: 14 [1800/2000 (90%)]\tLoss: 1.121543\n",
      "Epoch: 15 [0/2000 (0%)]\tLoss: 0.374076\n",
      "Epoch: 15 [200/2000 (10%)]\tLoss: 1.235187\n",
      "Epoch: 15 [400/2000 (20%)]\tLoss: 1.015993\n",
      "Epoch: 15 [600/2000 (30%)]\tLoss: 0.221285\n",
      "Epoch: 15 [800/2000 (40%)]\tLoss: 0.588304\n",
      "Epoch: 15 [1000/2000 (50%)]\tLoss: 0.246678\n",
      "Epoch: 15 [1200/2000 (60%)]\tLoss: 0.356057\n",
      "Epoch: 15 [1400/2000 (70%)]\tLoss: 0.116389\n",
      "Epoch: 15 [1600/2000 (80%)]\tLoss: 0.878153\n",
      "Epoch: 15 [1800/2000 (90%)]\tLoss: 0.738167\n",
      "Epoch: 16 [0/2000 (0%)]\tLoss: 0.451150\n",
      "Epoch: 16 [200/2000 (10%)]\tLoss: 0.450479\n",
      "Epoch: 16 [400/2000 (20%)]\tLoss: 1.288105\n",
      "Epoch: 16 [600/2000 (30%)]\tLoss: 0.190393\n",
      "Epoch: 16 [800/2000 (40%)]\tLoss: 0.180979\n",
      "Epoch: 16 [1000/2000 (50%)]\tLoss: 0.216697\n",
      "Epoch: 16 [1200/2000 (60%)]\tLoss: 0.922026\n",
      "Epoch: 16 [1400/2000 (70%)]\tLoss: 0.360668\n",
      "Epoch: 16 [1600/2000 (80%)]\tLoss: 0.313252\n",
      "Epoch: 16 [1800/2000 (90%)]\tLoss: 1.121739\n",
      "Epoch: 17 [0/2000 (0%)]\tLoss: 0.033673\n",
      "Epoch: 17 [200/2000 (10%)]\tLoss: 1.533358\n",
      "Epoch: 17 [400/2000 (20%)]\tLoss: 0.137988\n",
      "Epoch: 17 [600/2000 (30%)]\tLoss: 1.402298\n",
      "Epoch: 17 [800/2000 (40%)]\tLoss: 0.995924\n",
      "Epoch: 17 [1000/2000 (50%)]\tLoss: 0.095121\n",
      "Epoch: 17 [1200/2000 (60%)]\tLoss: 0.442460\n",
      "Epoch: 17 [1400/2000 (70%)]\tLoss: 0.220318\n",
      "Epoch: 17 [1600/2000 (80%)]\tLoss: 0.840837\n",
      "Epoch: 17 [1800/2000 (90%)]\tLoss: 0.190963\n",
      "Epoch: 18 [0/2000 (0%)]\tLoss: 0.418961\n",
      "Epoch: 18 [200/2000 (10%)]\tLoss: 0.278581\n",
      "Epoch: 18 [400/2000 (20%)]\tLoss: 0.101469\n",
      "Epoch: 18 [600/2000 (30%)]\tLoss: 0.089516\n",
      "Epoch: 18 [800/2000 (40%)]\tLoss: 1.191241\n",
      "Epoch: 18 [1000/2000 (50%)]\tLoss: 0.853559\n",
      "Epoch: 18 [1200/2000 (60%)]\tLoss: 0.123292\n",
      "Epoch: 18 [1400/2000 (70%)]\tLoss: 0.036788\n",
      "Epoch: 18 [1600/2000 (80%)]\tLoss: 0.233412\n",
      "Epoch: 18 [1800/2000 (90%)]\tLoss: 1.094530\n",
      "Epoch: 19 [0/2000 (0%)]\tLoss: 0.057824\n",
      "Epoch: 19 [200/2000 (10%)]\tLoss: 0.031369\n",
      "Epoch: 19 [400/2000 (20%)]\tLoss: 0.058933\n",
      "Epoch: 19 [600/2000 (30%)]\tLoss: 0.018510\n",
      "Epoch: 19 [800/2000 (40%)]\tLoss: 0.453590\n",
      "Epoch: 19 [1000/2000 (50%)]\tLoss: 0.363390\n",
      "Epoch: 19 [1200/2000 (60%)]\tLoss: 1.015295\n",
      "Epoch: 19 [1400/2000 (70%)]\tLoss: 0.012296\n",
      "Epoch: 19 [1600/2000 (80%)]\tLoss: 0.087988\n",
      "Epoch: 19 [1800/2000 (90%)]\tLoss: 0.666621\n",
      "Epoch: 20 [0/2000 (0%)]\tLoss: 0.196751\n",
      "Epoch: 20 [200/2000 (10%)]\tLoss: 0.840166\n",
      "Epoch: 20 [400/2000 (20%)]\tLoss: 0.074944\n",
      "Epoch: 20 [600/2000 (30%)]\tLoss: 0.384320\n",
      "Epoch: 20 [800/2000 (40%)]\tLoss: 0.013228\n",
      "Epoch: 20 [1000/2000 (50%)]\tLoss: 0.704184\n",
      "Epoch: 20 [1200/2000 (60%)]\tLoss: 0.057852\n",
      "Epoch: 20 [1400/2000 (70%)]\tLoss: 1.095666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 [1600/2000 (80%)]\tLoss: 0.303706\n",
      "Epoch: 20 [1800/2000 (90%)]\tLoss: 0.019550\n",
      "Epoch: 21 [0/2000 (0%)]\tLoss: 0.001746\n",
      "Epoch: 21 [200/2000 (10%)]\tLoss: 0.523292\n",
      "Epoch: 21 [400/2000 (20%)]\tLoss: 0.040975\n",
      "Epoch: 21 [600/2000 (30%)]\tLoss: 0.055294\n",
      "Epoch: 21 [800/2000 (40%)]\tLoss: 0.544001\n",
      "Epoch: 21 [1000/2000 (50%)]\tLoss: 0.316687\n",
      "Epoch: 21 [1200/2000 (60%)]\tLoss: 0.026984\n",
      "Epoch: 21 [1400/2000 (70%)]\tLoss: 0.136032\n",
      "Epoch: 21 [1600/2000 (80%)]\tLoss: 0.443502\n",
      "Epoch: 21 [1800/2000 (90%)]\tLoss: 0.670873\n",
      "Epoch: 22 [0/2000 (0%)]\tLoss: 0.833573\n",
      "Epoch: 22 [200/2000 (10%)]\tLoss: 0.048717\n",
      "Epoch: 22 [400/2000 (20%)]\tLoss: 1.043102\n",
      "Epoch: 22 [600/2000 (30%)]\tLoss: 0.038844\n",
      "Epoch: 22 [800/2000 (40%)]\tLoss: 0.329060\n",
      "Epoch: 22 [1000/2000 (50%)]\tLoss: 0.011750\n",
      "Epoch: 22 [1200/2000 (60%)]\tLoss: 0.036445\n",
      "Epoch: 22 [1400/2000 (70%)]\tLoss: 0.822783\n",
      "Epoch: 22 [1600/2000 (80%)]\tLoss: 0.038313\n",
      "Epoch: 22 [1800/2000 (90%)]\tLoss: 0.498139\n",
      "Epoch: 23 [0/2000 (0%)]\tLoss: 0.154353\n",
      "Epoch: 23 [200/2000 (10%)]\tLoss: 0.567473\n",
      "Epoch: 23 [400/2000 (20%)]\tLoss: 0.020053\n",
      "Epoch: 23 [600/2000 (30%)]\tLoss: 0.178764\n",
      "Epoch: 23 [800/2000 (40%)]\tLoss: 0.487373\n",
      "Epoch: 23 [1000/2000 (50%)]\tLoss: 0.175691\n",
      "Epoch: 23 [1200/2000 (60%)]\tLoss: 0.047683\n",
      "Epoch: 23 [1400/2000 (70%)]\tLoss: 0.192915\n",
      "Epoch: 23 [1600/2000 (80%)]\tLoss: 0.257808\n",
      "Epoch: 23 [1800/2000 (90%)]\tLoss: 0.016062\n",
      "Epoch: 24 [0/2000 (0%)]\tLoss: 0.441070\n",
      "Epoch: 24 [200/2000 (10%)]\tLoss: 0.052577\n",
      "Epoch: 24 [400/2000 (20%)]\tLoss: 0.457509\n",
      "Epoch: 24 [600/2000 (30%)]\tLoss: 0.027720\n",
      "Epoch: 24 [800/2000 (40%)]\tLoss: 0.099241\n",
      "Epoch: 24 [1000/2000 (50%)]\tLoss: 0.012857\n",
      "Epoch: 24 [1200/2000 (60%)]\tLoss: 0.188017\n",
      "Epoch: 24 [1400/2000 (70%)]\tLoss: 0.230679\n",
      "Epoch: 24 [1600/2000 (80%)]\tLoss: 0.452090\n",
      "Epoch: 24 [1800/2000 (90%)]\tLoss: 1.978856\n",
      "Epoch: 25 [0/2000 (0%)]\tLoss: 0.087478\n",
      "Epoch: 25 [200/2000 (10%)]\tLoss: 0.157917\n",
      "Epoch: 25 [400/2000 (20%)]\tLoss: 0.346087\n",
      "Epoch: 25 [600/2000 (30%)]\tLoss: 0.215126\n",
      "Epoch: 25 [800/2000 (40%)]\tLoss: 0.427435\n",
      "Epoch: 25 [1000/2000 (50%)]\tLoss: 0.385078\n",
      "Epoch: 25 [1200/2000 (60%)]\tLoss: 0.025287\n",
      "Epoch: 25 [1400/2000 (70%)]\tLoss: 0.812637\n",
      "Epoch: 25 [1600/2000 (80%)]\tLoss: 0.045094\n",
      "Epoch: 25 [1800/2000 (90%)]\tLoss: 0.310965\n",
      "Epoch: 26 [0/2000 (0%)]\tLoss: 0.243740\n",
      "Epoch: 26 [200/2000 (10%)]\tLoss: 0.302227\n",
      "Epoch: 26 [400/2000 (20%)]\tLoss: 0.015743\n",
      "Epoch: 26 [600/2000 (30%)]\tLoss: 0.502343\n",
      "Epoch: 26 [800/2000 (40%)]\tLoss: 0.186422\n",
      "Epoch: 26 [1000/2000 (50%)]\tLoss: 0.460208\n",
      "Epoch: 26 [1200/2000 (60%)]\tLoss: 0.000764\n",
      "Epoch: 26 [1400/2000 (70%)]\tLoss: 0.406445\n",
      "Epoch: 26 [1600/2000 (80%)]\tLoss: 0.001172\n",
      "Epoch: 26 [1800/2000 (90%)]\tLoss: 0.221487\n",
      "Epoch: 27 [0/2000 (0%)]\tLoss: 0.019368\n",
      "Epoch: 27 [200/2000 (10%)]\tLoss: 0.925121\n",
      "Epoch: 27 [400/2000 (20%)]\tLoss: 0.105685\n",
      "Epoch: 27 [600/2000 (30%)]\tLoss: 0.003359\n",
      "Epoch: 27 [800/2000 (40%)]\tLoss: 0.007857\n",
      "Epoch: 27 [1000/2000 (50%)]\tLoss: 0.001372\n",
      "Epoch: 27 [1200/2000 (60%)]\tLoss: 0.283937\n",
      "Epoch: 27 [1400/2000 (70%)]\tLoss: 0.000914\n",
      "Epoch: 27 [1600/2000 (80%)]\tLoss: 1.180994\n",
      "Epoch: 27 [1800/2000 (90%)]\tLoss: 0.270816\n",
      "Epoch: 28 [0/2000 (0%)]\tLoss: 0.006314\n",
      "Epoch: 28 [200/2000 (10%)]\tLoss: 0.001100\n",
      "Epoch: 28 [400/2000 (20%)]\tLoss: 0.098503\n",
      "Epoch: 28 [600/2000 (30%)]\tLoss: 0.001735\n",
      "Epoch: 28 [800/2000 (40%)]\tLoss: 0.000368\n",
      "Epoch: 28 [1000/2000 (50%)]\tLoss: 1.291529\n",
      "Epoch: 28 [1200/2000 (60%)]\tLoss: 0.005515\n",
      "Epoch: 28 [1400/2000 (70%)]\tLoss: 0.238815\n",
      "Epoch: 28 [1600/2000 (80%)]\tLoss: 0.340376\n",
      "Epoch: 28 [1800/2000 (90%)]\tLoss: 0.405002\n",
      "Epoch: 29 [0/2000 (0%)]\tLoss: 0.000131\n",
      "Epoch: 29 [200/2000 (10%)]\tLoss: 0.010396\n",
      "Epoch: 29 [400/2000 (20%)]\tLoss: 0.142040\n",
      "Epoch: 29 [600/2000 (30%)]\tLoss: 0.000093\n",
      "Epoch: 29 [800/2000 (40%)]\tLoss: 0.041762\n",
      "Epoch: 29 [1000/2000 (50%)]\tLoss: 0.144290\n",
      "Epoch: 29 [1200/2000 (60%)]\tLoss: 0.019429\n",
      "Epoch: 29 [1400/2000 (70%)]\tLoss: 0.274718\n",
      "Epoch: 29 [1600/2000 (80%)]\tLoss: 0.046547\n",
      "Epoch: 29 [1800/2000 (90%)]\tLoss: 0.001332\n",
      "Epoch: 30 [0/2000 (0%)]\tLoss: 0.284972\n",
      "Epoch: 30 [200/2000 (10%)]\tLoss: 0.441927\n",
      "Epoch: 30 [400/2000 (20%)]\tLoss: 0.019278\n",
      "Epoch: 30 [600/2000 (30%)]\tLoss: 0.333194\n",
      "Epoch: 30 [800/2000 (40%)]\tLoss: 0.005328\n",
      "Epoch: 30 [1000/2000 (50%)]\tLoss: 0.506737\n",
      "Epoch: 30 [1200/2000 (60%)]\tLoss: 1.139676\n",
      "Epoch: 30 [1400/2000 (70%)]\tLoss: 0.005217\n",
      "Epoch: 30 [1600/2000 (80%)]\tLoss: 0.003533\n",
      "Epoch: 30 [1800/2000 (90%)]\tLoss: 0.001224\n",
      "Epoch: 31 [0/2000 (0%)]\tLoss: 0.415450\n",
      "Epoch: 31 [200/2000 (10%)]\tLoss: 0.000254\n",
      "Epoch: 31 [400/2000 (20%)]\tLoss: 0.080311\n",
      "Epoch: 31 [600/2000 (30%)]\tLoss: 0.019505\n",
      "Epoch: 31 [800/2000 (40%)]\tLoss: 0.008814\n",
      "Epoch: 31 [1000/2000 (50%)]\tLoss: 0.000192\n",
      "Epoch: 31 [1200/2000 (60%)]\tLoss: 0.003360\n",
      "Epoch: 31 [1400/2000 (70%)]\tLoss: 0.093995\n",
      "Epoch: 31 [1600/2000 (80%)]\tLoss: 0.032178\n",
      "Epoch: 31 [1800/2000 (90%)]\tLoss: 0.098325\n",
      "Epoch: 32 [0/2000 (0%)]\tLoss: 0.006841\n",
      "Epoch: 32 [200/2000 (10%)]\tLoss: 0.026574\n",
      "Epoch: 32 [400/2000 (20%)]\tLoss: 0.052048\n",
      "Epoch: 32 [600/2000 (30%)]\tLoss: 0.342955\n",
      "Epoch: 32 [800/2000 (40%)]\tLoss: 0.014605\n",
      "Epoch: 32 [1000/2000 (50%)]\tLoss: 0.027521\n",
      "Epoch: 32 [1200/2000 (60%)]\tLoss: 0.020563\n",
      "Epoch: 32 [1400/2000 (70%)]\tLoss: 0.005692\n",
      "Epoch: 32 [1600/2000 (80%)]\tLoss: 0.002245\n",
      "Epoch: 32 [1800/2000 (90%)]\tLoss: 0.002848\n",
      "Epoch: 33 [0/2000 (0%)]\tLoss: 0.010706\n",
      "Epoch: 33 [200/2000 (10%)]\tLoss: 0.001883\n",
      "Epoch: 33 [400/2000 (20%)]\tLoss: 0.158522\n",
      "Epoch: 33 [600/2000 (30%)]\tLoss: 0.007029\n",
      "Epoch: 33 [800/2000 (40%)]\tLoss: 0.072728\n",
      "Epoch: 33 [1000/2000 (50%)]\tLoss: 0.000242\n",
      "Epoch: 33 [1200/2000 (60%)]\tLoss: 0.003018\n",
      "Epoch: 33 [1400/2000 (70%)]\tLoss: 0.002463\n",
      "Epoch: 33 [1600/2000 (80%)]\tLoss: 0.014972\n",
      "Epoch: 33 [1800/2000 (90%)]\tLoss: 0.157734\n",
      "Epoch: 34 [0/2000 (0%)]\tLoss: 0.189872\n",
      "Epoch: 34 [200/2000 (10%)]\tLoss: 0.000815\n",
      "Epoch: 34 [400/2000 (20%)]\tLoss: 0.003588\n",
      "Epoch: 34 [600/2000 (30%)]\tLoss: 0.022006\n",
      "Epoch: 34 [800/2000 (40%)]\tLoss: 0.003515\n",
      "Epoch: 34 [1000/2000 (50%)]\tLoss: 0.000323\n",
      "Epoch: 34 [1200/2000 (60%)]\tLoss: 0.022566\n",
      "Epoch: 34 [1400/2000 (70%)]\tLoss: 0.003424\n",
      "Epoch: 34 [1600/2000 (80%)]\tLoss: 0.002264\n",
      "Epoch: 34 [1800/2000 (90%)]\tLoss: 0.001703\n",
      "Epoch: 35 [0/2000 (0%)]\tLoss: 0.005419\n",
      "Epoch: 35 [200/2000 (10%)]\tLoss: 0.002515\n",
      "Epoch: 35 [400/2000 (20%)]\tLoss: 0.487792\n",
      "Epoch: 35 [600/2000 (30%)]\tLoss: 0.028550\n",
      "Epoch: 35 [800/2000 (40%)]\tLoss: 0.112294\n",
      "Epoch: 35 [1000/2000 (50%)]\tLoss: 0.078040\n",
      "Epoch: 35 [1200/2000 (60%)]\tLoss: 0.004060\n",
      "Epoch: 35 [1400/2000 (70%)]\tLoss: 0.079159\n",
      "Epoch: 35 [1600/2000 (80%)]\tLoss: 0.040102\n",
      "Epoch: 35 [1800/2000 (90%)]\tLoss: 0.000105\n",
      "Epoch: 36 [0/2000 (0%)]\tLoss: 0.074947\n",
      "Epoch: 36 [200/2000 (10%)]\tLoss: 0.248722\n",
      "Epoch: 36 [400/2000 (20%)]\tLoss: 0.501055\n",
      "Epoch: 36 [600/2000 (30%)]\tLoss: 0.000349\n",
      "Epoch: 36 [800/2000 (40%)]\tLoss: 0.000427\n",
      "Epoch: 36 [1000/2000 (50%)]\tLoss: 0.002657\n",
      "Epoch: 36 [1200/2000 (60%)]\tLoss: 0.224517\n",
      "Epoch: 36 [1400/2000 (70%)]\tLoss: 0.000486\n",
      "Epoch: 36 [1600/2000 (80%)]\tLoss: 0.013928\n",
      "Epoch: 36 [1800/2000 (90%)]\tLoss: 0.006530\n",
      "Epoch: 37 [0/2000 (0%)]\tLoss: 0.825701\n",
      "Epoch: 37 [200/2000 (10%)]\tLoss: 0.331937\n",
      "Epoch: 37 [400/2000 (20%)]\tLoss: 0.017340\n",
      "Epoch: 37 [600/2000 (30%)]\tLoss: 0.217760\n",
      "Epoch: 37 [800/2000 (40%)]\tLoss: 0.001835\n",
      "Epoch: 37 [1000/2000 (50%)]\tLoss: 0.000127\n",
      "Epoch: 37 [1200/2000 (60%)]\tLoss: 0.000427\n",
      "Epoch: 37 [1400/2000 (70%)]\tLoss: 0.310222\n",
      "Epoch: 37 [1600/2000 (80%)]\tLoss: 0.086027\n",
      "Epoch: 37 [1800/2000 (90%)]\tLoss: 0.004284\n",
      "Epoch: 38 [0/2000 (0%)]\tLoss: 0.001192\n",
      "Epoch: 38 [200/2000 (10%)]\tLoss: 0.002832\n",
      "Epoch: 38 [400/2000 (20%)]\tLoss: 0.090890\n",
      "Epoch: 38 [600/2000 (30%)]\tLoss: 0.001133\n",
      "Epoch: 38 [800/2000 (40%)]\tLoss: 0.004758\n",
      "Epoch: 38 [1000/2000 (50%)]\tLoss: 0.002619\n",
      "Epoch: 38 [1200/2000 (60%)]\tLoss: 0.001437\n",
      "Epoch: 38 [1400/2000 (70%)]\tLoss: 0.092976\n",
      "Epoch: 38 [1600/2000 (80%)]\tLoss: 0.130247\n",
      "Epoch: 38 [1800/2000 (90%)]\tLoss: 0.000347\n",
      "Epoch: 39 [0/2000 (0%)]\tLoss: 0.054377\n",
      "Epoch: 39 [200/2000 (10%)]\tLoss: 0.002326\n",
      "Epoch: 39 [400/2000 (20%)]\tLoss: 0.004608\n",
      "Epoch: 39 [600/2000 (30%)]\tLoss: 0.001277\n",
      "Epoch: 39 [800/2000 (40%)]\tLoss: 0.035928\n",
      "Epoch: 39 [1000/2000 (50%)]\tLoss: 0.027903\n",
      "Epoch: 39 [1200/2000 (60%)]\tLoss: 0.006778\n",
      "Epoch: 39 [1400/2000 (70%)]\tLoss: 0.000263\n",
      "Epoch: 39 [1600/2000 (80%)]\tLoss: 0.751141\n",
      "Epoch: 39 [1800/2000 (90%)]\tLoss: 0.001044\n",
      "Epoch: 40 [0/2000 (0%)]\tLoss: 0.000154\n",
      "Epoch: 40 [200/2000 (10%)]\tLoss: 0.000449\n",
      "Epoch: 40 [400/2000 (20%)]\tLoss: 0.043173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 [600/2000 (30%)]\tLoss: 0.003644\n",
      "Epoch: 40 [800/2000 (40%)]\tLoss: 0.001426\n",
      "Epoch: 40 [1000/2000 (50%)]\tLoss: 0.000937\n",
      "Epoch: 40 [1200/2000 (60%)]\tLoss: 0.009073\n",
      "Epoch: 40 [1400/2000 (70%)]\tLoss: 0.000434\n",
      "Epoch: 40 [1600/2000 (80%)]\tLoss: 0.145900\n",
      "Epoch: 40 [1800/2000 (90%)]\tLoss: 0.101054\n",
      "Epoch: 41 [0/2000 (0%)]\tLoss: 0.020715\n",
      "Epoch: 41 [200/2000 (10%)]\tLoss: 0.001798\n",
      "Epoch: 41 [400/2000 (20%)]\tLoss: 0.013274\n",
      "Epoch: 41 [600/2000 (30%)]\tLoss: 0.001734\n",
      "Epoch: 41 [800/2000 (40%)]\tLoss: 0.063425\n",
      "Epoch: 41 [1000/2000 (50%)]\tLoss: 0.002083\n",
      "Epoch: 41 [1200/2000 (60%)]\tLoss: 0.000211\n",
      "Epoch: 41 [1400/2000 (70%)]\tLoss: 0.001660\n",
      "Epoch: 41 [1600/2000 (80%)]\tLoss: 0.000005\n",
      "Epoch: 41 [1800/2000 (90%)]\tLoss: 0.070718\n",
      "Epoch: 42 [0/2000 (0%)]\tLoss: 0.113709\n",
      "Epoch: 42 [200/2000 (10%)]\tLoss: 0.172816\n",
      "Epoch: 42 [400/2000 (20%)]\tLoss: 0.129520\n",
      "Epoch: 42 [600/2000 (30%)]\tLoss: 0.005254\n",
      "Epoch: 42 [800/2000 (40%)]\tLoss: 0.004954\n",
      "Epoch: 42 [1000/2000 (50%)]\tLoss: 0.052726\n",
      "Epoch: 42 [1200/2000 (60%)]\tLoss: 0.441510\n",
      "Epoch: 42 [1400/2000 (70%)]\tLoss: 0.036256\n",
      "Epoch: 42 [1600/2000 (80%)]\tLoss: 0.018892\n",
      "Epoch: 42 [1800/2000 (90%)]\tLoss: 0.001133\n",
      "Epoch: 43 [0/2000 (0%)]\tLoss: 0.008534\n",
      "Epoch: 43 [200/2000 (10%)]\tLoss: 0.018904\n",
      "Epoch: 43 [400/2000 (20%)]\tLoss: 0.059775\n",
      "Epoch: 43 [600/2000 (30%)]\tLoss: 0.001598\n",
      "Epoch: 43 [800/2000 (40%)]\tLoss: 0.004360\n",
      "Epoch: 43 [1000/2000 (50%)]\tLoss: 0.001239\n",
      "Epoch: 43 [1200/2000 (60%)]\tLoss: 0.001440\n",
      "Epoch: 43 [1400/2000 (70%)]\tLoss: 0.007609\n",
      "Epoch: 43 [1600/2000 (80%)]\tLoss: 0.000636\n",
      "Epoch: 43 [1800/2000 (90%)]\tLoss: 0.002514\n",
      "Epoch: 44 [0/2000 (0%)]\tLoss: 0.000167\n",
      "Epoch: 44 [200/2000 (10%)]\tLoss: 0.000243\n",
      "Epoch: 44 [400/2000 (20%)]\tLoss: 0.000220\n",
      "Epoch: 44 [600/2000 (30%)]\tLoss: 0.014371\n",
      "Epoch: 44 [800/2000 (40%)]\tLoss: 0.000231\n",
      "Epoch: 44 [1000/2000 (50%)]\tLoss: 0.000191\n",
      "Epoch: 44 [1200/2000 (60%)]\tLoss: 0.000148\n",
      "Epoch: 44 [1400/2000 (70%)]\tLoss: 0.000411\n",
      "Epoch: 44 [1600/2000 (80%)]\tLoss: 0.000090\n",
      "Epoch: 44 [1800/2000 (90%)]\tLoss: 0.002003\n",
      "Epoch: 45 [0/2000 (0%)]\tLoss: 0.000456\n",
      "Epoch: 45 [200/2000 (10%)]\tLoss: 0.082767\n",
      "Epoch: 45 [400/2000 (20%)]\tLoss: 0.001307\n",
      "Epoch: 45 [600/2000 (30%)]\tLoss: 0.000346\n",
      "Epoch: 45 [800/2000 (40%)]\tLoss: 0.018861\n",
      "Epoch: 45 [1000/2000 (50%)]\tLoss: 0.003913\n",
      "Epoch: 45 [1200/2000 (60%)]\tLoss: 0.001785\n",
      "Epoch: 45 [1400/2000 (70%)]\tLoss: 0.000080\n",
      "Epoch: 45 [1600/2000 (80%)]\tLoss: 0.001845\n",
      "Epoch: 45 [1800/2000 (90%)]\tLoss: 0.000473\n",
      "Epoch: 46 [0/2000 (0%)]\tLoss: 0.012922\n",
      "Epoch: 46 [200/2000 (10%)]\tLoss: 0.041507\n",
      "Epoch: 46 [400/2000 (20%)]\tLoss: 0.009424\n",
      "Epoch: 46 [600/2000 (30%)]\tLoss: 0.000039\n",
      "Epoch: 46 [800/2000 (40%)]\tLoss: 0.001973\n",
      "Epoch: 46 [1000/2000 (50%)]\tLoss: 0.277191\n",
      "Epoch: 46 [1200/2000 (60%)]\tLoss: 0.001505\n",
      "Epoch: 46 [1400/2000 (70%)]\tLoss: 0.060679\n",
      "Epoch: 46 [1600/2000 (80%)]\tLoss: 0.935677\n",
      "Epoch: 46 [1800/2000 (90%)]\tLoss: 0.003138\n",
      "Epoch: 47 [0/2000 (0%)]\tLoss: 0.013128\n",
      "Epoch: 47 [200/2000 (10%)]\tLoss: 0.001677\n",
      "Epoch: 47 [400/2000 (20%)]\tLoss: 0.000409\n",
      "Epoch: 47 [600/2000 (30%)]\tLoss: 0.001654\n",
      "Epoch: 47 [800/2000 (40%)]\tLoss: 0.684817\n",
      "Epoch: 47 [1000/2000 (50%)]\tLoss: 0.012417\n",
      "Epoch: 47 [1200/2000 (60%)]\tLoss: 0.189707\n",
      "Epoch: 47 [1400/2000 (70%)]\tLoss: 0.020886\n",
      "Epoch: 47 [1600/2000 (80%)]\tLoss: 0.034114\n",
      "Epoch: 47 [1800/2000 (90%)]\tLoss: 0.049552\n",
      "Epoch: 48 [0/2000 (0%)]\tLoss: 0.007243\n",
      "Epoch: 48 [200/2000 (10%)]\tLoss: 0.000074\n",
      "Epoch: 48 [400/2000 (20%)]\tLoss: 0.000322\n",
      "Epoch: 48 [600/2000 (30%)]\tLoss: 0.001619\n",
      "Epoch: 48 [800/2000 (40%)]\tLoss: 0.001292\n",
      "Epoch: 48 [1000/2000 (50%)]\tLoss: 0.001625\n",
      "Epoch: 48 [1200/2000 (60%)]\tLoss: 0.420109\n",
      "Epoch: 48 [1400/2000 (70%)]\tLoss: 0.001802\n",
      "Epoch: 48 [1600/2000 (80%)]\tLoss: 0.018439\n",
      "Epoch: 48 [1800/2000 (90%)]\tLoss: 0.007880\n",
      "Epoch: 49 [0/2000 (0%)]\tLoss: 0.000110\n",
      "Epoch: 49 [200/2000 (10%)]\tLoss: 0.755227\n",
      "Epoch: 49 [400/2000 (20%)]\tLoss: 0.002040\n",
      "Epoch: 49 [600/2000 (30%)]\tLoss: 0.006249\n",
      "Epoch: 49 [800/2000 (40%)]\tLoss: 0.000202\n",
      "Epoch: 49 [1000/2000 (50%)]\tLoss: 0.002228\n",
      "Epoch: 49 [1200/2000 (60%)]\tLoss: 0.002456\n",
      "Epoch: 49 [1400/2000 (70%)]\tLoss: 0.003692\n",
      "Epoch: 49 [1600/2000 (80%)]\tLoss: 0.000781\n",
      "Epoch: 49 [1800/2000 (90%)]\tLoss: 0.001732\n",
      "Epoch: 50 [0/2000 (0%)]\tLoss: 0.002577\n",
      "Epoch: 50 [200/2000 (10%)]\tLoss: 0.013356\n",
      "Epoch: 50 [400/2000 (20%)]\tLoss: 0.023493\n",
      "Epoch: 50 [600/2000 (30%)]\tLoss: 0.000173\n",
      "Epoch: 50 [800/2000 (40%)]\tLoss: 0.000989\n",
      "Epoch: 50 [1000/2000 (50%)]\tLoss: 0.000041\n",
      "Epoch: 50 [1200/2000 (60%)]\tLoss: 0.000150\n",
      "Epoch: 50 [1400/2000 (70%)]\tLoss: 0.005763\n",
      "Epoch: 50 [1600/2000 (80%)]\tLoss: 0.000055\n",
      "Epoch: 50 [1800/2000 (90%)]\tLoss: 0.000131\n",
      "Finished training in  624.275 seconds \n",
      "\n",
      "Test set: Average loss: 0.9403, Accuracy: 33/100 (33%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa75f5fda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "#Import\n",
    "data_transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "train_set = datasets.ImageFolder(root='clouds_hard',\n",
    "                                transform=data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=1)\n",
    "\n",
    "test_set = datasets.ImageFolder(root='clouds_hard_test',\n",
    "                                transform=data_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                             batch_size=4,shuffle=False,\n",
    "                                             num_workers=1)\n",
    "\n",
    "cloud_classes = ('0', 'pi/4', 'pi/2', '3pi/4')\n",
    "\n",
    "#Model\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(32 * 32, 200)\n",
    "            self.fc2 = nn.Linear(200, 200)\n",
    "            self.fc3 = nn.Linear(200, 4)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return F.log_softmax(input=x)\n",
    "model = Net()\n",
    "\n",
    "#Optimizer\n",
    "import torch.optim as optim\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#Training\n",
    "import time\n",
    "start_time = time.time()\n",
    "print(\"Started training\")\n",
    "\n",
    "epochs = 50\n",
    "print_interval = 50\n",
    "tempo = []\n",
    "acc = []\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    for batch_idx, (data, target) in enumerate(train_loader): \n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        data = data.view(-1, 32*32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        net_out = model(data)\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % print_interval == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "    tempo.append(epoch)\n",
    "    acc.append(loss.data[0])\n",
    "    \n",
    "print(\"Finished training in  %.3f seconds \" % (time.time() - start_time))\n",
    "\n",
    "#Testing\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    \n",
    "    data = data.view(-1, 32 * 32)\n",
    "    net_out = model(data)\n",
    "    \n",
    "    test_loss += criterion(net_out, target).data[0]\n",
    "    pred = net_out.data.max(1)[1]\n",
    "    correct += pred.eq(target.data).sum() \n",
    "\n",
    "test_loss /= len(test_loader.dataset) \n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "#Saving\n",
    "torch.save(model.state_dict(), \"MODEL_trainHARD_pytorchMCV2\")\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tempo, acc)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss variation - Hard training')\n",
    "plt.savefig('Loss_hardtraining.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
