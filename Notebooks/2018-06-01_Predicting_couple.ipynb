{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-06-01 - Prédire un couple Theta/B_theta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération MC\n",
    "Pour utiliser les deux propriétés il faut générer le couple theta_btheta directement dans le nom du folder et ensuite récupérer le label avec set.class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Btheta list : \n",
      "[0.02454369 0.02709843 0.0299191  0.03303336 0.03647179 0.04026812\n",
      " 0.04445961 0.04908739 0.05419687 0.05983819 0.06606672 0.07294357\n",
      " 0.08053624 0.08891921 0.09817477 0.10839373 0.11967639 0.13213344\n",
      " 0.14588715 0.16107247 0.17783843 0.19634954 0.21678747 0.23935277\n",
      " 0.26426688 0.2917743  0.32214494 0.35567685 0.39269908 0.43357494\n",
      " 0.47870554 0.52853377 0.58354859 0.64428988 0.7113537  0.78539816\n",
      " 0.86714988 0.95741109 1.05706754 1.16709719 1.28857976 1.4227074\n",
      " 1.57079633 1.73429975 1.91482217 2.11413508 2.33419437 2.57715953\n",
      " 2.84541481 3.14159265]\n",
      "theta list : \n",
      "[0.         0.19634954 0.39269908 0.58904862 0.78539816 0.9817477\n",
      " 1.17809725 1.37444679 1.57079633 1.76714587 1.96349541 2.15984495\n",
      " 2.35619449 2.55254403 2.74889357 2.94524311]\n"
     ]
    }
   ],
   "source": [
    "import MotionClouds as mc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "#MC params\n",
    "downscale = 1\n",
    "fx, fy, ft = mc.get_grids(mc.N_X/downscale, mc.N_Y/downscale, 1)\n",
    "\n",
    "#generation params\n",
    "N_folders = 50\n",
    "N_mc = 5\n",
    "\n",
    "b_thetas = np.pi*np.logspace(-7, 0, N_folders, base=2)\n",
    "\n",
    "thetas = np.linspace(0, np.pi, 16, endpoint=False)\n",
    "\n",
    "\n",
    "print('Btheta list : \\n'+str( b_thetas))\n",
    "print('theta list : \\n'+str(thetas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating clouds...\n",
      "Clouds generated !\n",
      "Generating test set ...\n",
      "Test set generated !\n"
     ]
    }
   ],
   "source": [
    "path = 'clouds_couple'\n",
    "\n",
    "print('Generating clouds...')\n",
    "#loop through b_thetas and thetas\n",
    "for i_btheta, B_theta in enumerate(b_thetas) :\n",
    "    for i_theta, theta in enumerate(thetas) :\n",
    "        if not os.path.exists('./%s/b%st%s' % (path, B_theta*180/np.pi, theta*180/np.pi)): #folders are of shape 0b0\n",
    "            os.makedirs('./%s/b%st%s' % (path, B_theta*180/np.pi, theta*180/np.pi))\n",
    "        \n",
    "        mc_i = mc.envelope_gabor(fx, fy, ft, V_X=0., V_Y=0., B_V=0, theta=theta, B_theta=B_theta)\n",
    "        im = mc.random_cloud(mc_i)\n",
    "        im = (mc.rectif(im) * 255).astype('uint8')\n",
    "        imageio.imwrite('./%s/b%st%s/%s.png' % (path, B_theta*180/np.pi , theta*180/np.pi, str('MC')),\n",
    "                        im[:, :, 0])\n",
    "print('Clouds generated !')\n",
    "\n",
    "path = 'clouds_couple_test'\n",
    "N_folders = 5\n",
    "\n",
    "b_thetas = np.pi*np.logspace(-7, 0, N_folders, base=2)\n",
    "thetas = np.linspace(0, np.pi, 16, endpoint=False)\n",
    "print('Generating test set ...')\n",
    "for i_btheta, B_theta in enumerate(b_thetas) :\n",
    "    for i_theta, theta in enumerate(thetas) :\n",
    "        if not os.path.exists('./%s/b%st%s' % (path, B_theta*180/np.pi, theta*180/np.pi)): #folders are of shape 0b0\n",
    "            os.makedirs('./%s/b%st%s' % (path, B_theta*180/np.pi, theta*180/np.pi))\n",
    "        \n",
    "        mc_i = mc.envelope_gabor(fx, fy, ft, V_X=0., V_Y=0., B_V=0, theta=theta, B_theta=B_theta)\n",
    "        im = mc.random_cloud(mc_i)\n",
    "        im = (mc.rectif(im) * 255).astype('uint8')\n",
    "        imageio.imwrite('./%s/b%st%s/%s.png' % (path, B_theta*180/np.pi , theta*180/np.pi, str('MC')),\n",
    "                        im[:, :, 0])\n",
    "print('Test set generated !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau convolutionnel\n",
    "Maintenant on va tenter de prédire les couples en utilisant le réseau convolutionnel classique à 5 couches, utilisé en première semaine :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=1690, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "#Transform\n",
    "data_transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 10, 5)\n",
    "        self.fc1 = nn.Linear(1690, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.fc3 = nn.Linear(100, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7])\n",
      "tensor([  8,   9,  10,  11,  12,  13,  14,  15])\n",
      "tensor([ 16,  17,  18,  19,  20,  21,  22,  23])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THNN/generic/ClassNLLCriterion.c:97",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-9807b2e7b9d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 759\u001b[0;31m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \"\"\"\n\u001b[0;32m-> 1442\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THNN/generic/ClassNLLCriterion.c:97"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#Train\n",
    "train_set = datasets.ImageFolder(root='clouds_couple',\n",
    "                                transform=data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                             batch_size=8, shuffle=False,\n",
    "                                             num_workers=1)\n",
    "#Test\n",
    "test_set = datasets.ImageFolder(root='clouds_couple_test',\n",
    "                                transform=data_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                             batch_size=8,shuffle=False,\n",
    "                                             num_workers=1)\n",
    "\n",
    "#Plotting lists\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "time_list = []\n",
    "t=0\n",
    "\n",
    "#Hyperparameters\n",
    "epochs = 10\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "print(\"Started training\")\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, epochs, i+1, total_step, loss.data[0]))\n",
    "            loss_list.append(loss.data[0])\n",
    "            time_list.append(t)\n",
    "            t+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
