{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-06-08 - Comparaison modèle/humain\n",
    "# Pour génerer les MC  : 2018-06-17 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.Resize((128,128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "#train\n",
    "train_set = datasets.ImageFolder(root='16_clouds_easy',\n",
    "                                transform=data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=1, drop_last = True)\n",
    "\n",
    "#test\n",
    "test_set = datasets.ImageFolder(root='16_clouds_easy_test',\n",
    "                                transform=data_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                             batch_size=4,shuffle=True,\n",
    "                                             num_workers=1, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 20)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc3 = nn.Linear(17496,1000)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.outlayer = nn.Linear(1000,16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1) #reshape from conv to linear\n",
    "\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.outlayer(x)\n",
    "        return x\n",
    "        \n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze layers after and including freezing_layer+1 (layers start at 0)\n",
    "def freeze_layers(freezing_layer, nn_model = model) :\n",
    "    for count,child in enumerate(model.children()) :\n",
    "        if  count < freezing_layer+1 : #to freeze at iteration 1\n",
    "            print(\"Layer no. %s -- %s -- NOT FROZEN\"% (count,child))\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        else :\n",
    "            print(\"Layer no. %s -- %s -- FROZEN\"%(count, child))\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "#freeze all the layers except the unfrozen one\n",
    "def freeze_all_layers(unfrozen_layer, nn_model = model) :\n",
    "    for count,child in enumerate(model.children()) :\n",
    "        if count == unfrozen_layer :\n",
    "            print(\"Layer no. %s -- %s -- NOT FROZEN\"% (count,child))\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        else :\n",
    "            print(\"Layer no. %s -- %s -- FROZEN\"%(count, child))\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "#unfreeze every layers\n",
    "def layers_microwave(nn_model = model) :\n",
    "    for count,child in enumerate(model.children()) :\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "#unfreeze before starting\n",
    "layers_microwave(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #loss criterion\n",
    "optimizer = optim.SGD(params = model.parameters(),lr=0.001, momentum=0.9)\n",
    "epochs = 2 #nbr of epochs per layer\n",
    "model_size = 4 #nbr of layers\n",
    "\n",
    "print_interval = 50 #prints every p_i*4\n",
    "tempo = []\n",
    "acc = []\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Started training\")\n",
    "\n",
    "for epoch in range(epochs):  # nbr epochs\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): #nbr batch,in,out\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #On resize pour la sortie\n",
    "\n",
    "\n",
    "        #init l'entrainement\n",
    "        optimizer.zero_grad()\n",
    "        net_out = model(data)\n",
    "\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #afficher la progression\n",
    "        if batch_idx % print_interval == 0:\n",
    "            #le print statement le plus illisible du monde\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\t\\tLoss: {:.6f}'.format(\n",
    "                    epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "    tempo.append(epoch)\n",
    "    acc.append(loss.data[0])\n",
    "\n",
    "\n",
    "print(\"Finished training in  %.3f seconds \" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "model = model.eval()\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "\n",
    "    net_out = model(data)\n",
    "    \n",
    "    #somme des pertes du batch\n",
    "    test_loss += criterion(net_out, target).data[0]\n",
    "    pred = net_out.data.max(1)[1] #prediction\n",
    "    correct += pred.eq(target.data).sum() #output du réseau\n",
    "\n",
    "test_loss /= len(test_loader.dataset) #loss = loss/length set\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convo - Psychophysique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T05:00:27.119575Z",
     "start_time": "2018-06-06T05:00:27.115853Z"
    }
   },
   "outputs": [],
   "source": [
    "#j'ai augmenté les B_theta et la longueur du test pour lisser les courbes\n",
    "exp_info = 'convo_model_HIRES'\n",
    "print (exp_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On défini la génération de MotionClouds :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T05:00:27.654957Z",
     "start_time": "2018-06-06T05:00:27.121708Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MotionClouds as mc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio\n",
    "import random\n",
    "\n",
    "downscale = 1\n",
    "fig_width = 21\n",
    "fx, fy, ft = mc.get_grids(mc.N_X/downscale, mc.N_Y/downscale, 1)\n",
    "\n",
    "# generates a cloud of given theta and b_theta\n",
    "def generate_random_cloud(theta, B_theta):\n",
    "    mc_i = mc.envelope_gabor(fx, fy, ft, V_X=0., V_Y=0.,\n",
    "                             B_V=0, theta=theta, B_theta=B_theta)\n",
    "    im = mc.random_cloud(mc_i)\n",
    "    im = (mc.rectif(im) * 255).astype('uint8')\n",
    "    fname = './tmp/%s_%s.png' % (theta, B_theta)\n",
    "    imageio.imwrite(fname, im[:, :, 0])\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit les paramètres et on teste :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T05:03:33.668425Z",
     "start_time": "2018-06-06T05:00:29.907308Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from psychopy import visual, core, event\n",
    "import MotionClouds as MC\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimage\n",
    "from PIL import Image\n",
    "\n",
    "test_length = 600\n",
    "MC1 = generate_random_cloud(np.pi/2, B_theta=np.pi/2)\n",
    "model = model.eval()\n",
    "\n",
    "\n",
    "ans_list = []\n",
    "N_B_thetas = 15\n",
    "B_thetas = np.pi*np.logspace(-6, -1, N_B_thetas, base=2)\n",
    "    \n",
    "std_theta = np.pi/6\n",
    "\n",
    "for trial in range(test_length):\n",
    "    theta = np.clip(std_theta *  np.random.randn(), -np.pi/4, np.pi/4)\n",
    "\n",
    "    # MC generation\n",
    "    B_theta = B_thetas[random.randint(0, N_B_thetas-1)]\n",
    "\n",
    "    MC1 = generate_random_cloud(np.pi/2, B_theta=B_theta)\n",
    "    MC2 = generate_random_cloud(np.pi/2 - theta, B_theta=B_theta)  # if shift = 2\n",
    "\n",
    "    varimgmc2 = data_transform(Image.open(MC2))\n",
    "    #varimgmc2 = data_transform(Image.open('16_clouds_easy/0.0/B0 1.40625.png'))\n",
    "    varimgmc2 = Variable(varimgmc2)\n",
    "    varimgmc2 = varimgmc2.unsqueeze(0)\n",
    "    \n",
    "    net_ans = model(varimgmc2)\n",
    "    pred = net_ans.data.max(1)[1] #prediction\n",
    "    #print(pred)\n",
    "    #correct = (np.sign(theta) > 0) and (pred[0]>8)\n",
    "    if np.sign(theta) > 0 and pred[0] > 8 :\n",
    "        correct = True\n",
    "    if np.sign(theta) < 0 and pred[0] <= 8:\n",
    "        correct = True\n",
    "    else :\n",
    "        correct = False\n",
    "    print('At trial ', trial, 'Angle=', '%3.3f' % (theta*180/np.pi), 'answer is ', pred[0], '(correct=', correct, '); bandwidth=', '%.3f' % (B_theta*180/np.pi))\n",
    "\n",
    "    # Output shape per trial is : trial number, shift direction, answered shift and b_theta\n",
    "    if pred[0] >8 :\n",
    "        ans_list.append([trial, theta, 'left', B_theta])\n",
    "    if pred[0] <= 8 :\n",
    "        ans_list.append([trial, theta, 'right', B_theta])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "pickle.dump(ans_list, open('./psychophysics_data/Psy_discrim_final_%s.p' % exp_info, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le Ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue May 15 11:25:41 2018\n",
    "\n",
    "@author: hugo\n",
    "\"\"\"\n",
    "from torch.autograd import Variable\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Transform\n",
    "data_transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "#Train\n",
    "train_set = datasets.ImageFolder(root='16_clouds_easy',\n",
    "                                transform=data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                             batch_size=8, shuffle=True,\n",
    "                                             num_workers=1)\n",
    "\n",
    "#Test\n",
    "test_set = datasets.ImageFolder(root='16_clouds_easy_test',\n",
    "                                transform=data_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                             batch_size=8,shuffle=False,\n",
    "                                             num_workers=1)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "# Hyper-parameters\n",
    "sequence_length = 49\n",
    "input_size = 49\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 16\n",
    "batch_size = 8\n",
    "num_epochs = 60\n",
    "learning_rate = 0.003\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout = 0.3)\n",
    "        self.conv1 = nn.Conv2d(1,8,30)\n",
    "        self.conv2 = nn.Conv2d(1,8,30)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        #self.drop = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc = nn.Linear(113 , 16)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print('Input %s' % str(x.size()))\n",
    "\n",
    "        out = self.pool1(F.relu(self.conv1(x)))\n",
    "        #print('Convoluted %s' % str(x.size()))\n",
    "\n",
    "        # Init\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "        h0 = Variable(h0).cuda()\n",
    "        c0 = Variable(c0).cuda()\n",
    "        \n",
    "        out = out[:,-1,:,:]\n",
    "        #print('Resized for RNN %s' % str(x.size()))\n",
    "        \n",
    "        # LSTM forward\n",
    "        out, _ = self.rnn(out, (h0,c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        #print('After RNN %s' % str(out.size()))\n",
    "        \n",
    "        out = out.unsqueeze(1)\n",
    "        #print(out.size())\n",
    "        out = self.pool2(F.relu(self.conv2(out)))\n",
    "        #print(out.size())\n",
    "        out = out[:,-1,:,:]\n",
    "        #Dropout\n",
    "        #out = self.drop(out)\n",
    "        #print(out.size())\n",
    "        \n",
    "        out = out[:,-1,:]\n",
    "        # LSTM output\n",
    "        out = self.fc(out)\n",
    "        #print('Reshaped for output %s \\n'%  str(out.size()))\n",
    "\n",
    "        return out\n",
    "\n",
    "model = BiRNN(input_size, hidden_size, num_layers, num_classes).cuda()\n",
    "print(model)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "#plotting list\n",
    "loss_list = []\n",
    "time_list = []\n",
    "t = 0\n",
    "\n",
    "print(\"Start training\")\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for param in model.rnn.parameters() :\n",
    "    param.requires_grad = False\n",
    "for epoch in range(num_epochs):\n",
    "     \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        freeze_layers\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.data[0]))\n",
    "            loss_list.append(loss.data[0])\n",
    "            time_list.append(t)\n",
    "            t+=1\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images).cuda()\n",
    "    labels = Variable(labels).cuda()\n",
    "\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels.data).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.asarray(time_list)[::4], loss_list)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for LSTM-CNN')\n",
    "plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW FOR THE PSYCHOPHYSICS\n",
    "import numpy as np\n",
    "import MotionClouds as mc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio\n",
    "import random\n",
    "\n",
    "exp_info = 'model_ring_HIRES'\n",
    "print (exp_info)\n",
    "\n",
    "downscale = 1\n",
    "fig_width = 21\n",
    "fx, fy, ft = mc.get_grids(mc.N_X/downscale, mc.N_Y/downscale, 1)\n",
    "\n",
    "# generates a cloud of given theta and b_theta\n",
    "def generate_random_cloud(theta, B_theta):\n",
    "    mc_i = mc.envelope_gabor(fx, fy, ft, V_X=0., V_Y=0.,\n",
    "                             B_V=0, theta=theta, B_theta=B_theta)\n",
    "    \n",
    "    im = mc.random_cloud(mc_i)\n",
    "    im = (mc.rectif(im) * 255).astype('uint8')\n",
    "    fname = './tmp/%s_%s.bmp' % (theta, B_theta)\n",
    "    imageio.imwrite(uri = fname,im = im[:, :, 0], format = 'bmp')\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psychopy import visual, core, event\n",
    "import MotionClouds as MC\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "files = glob.glob('./tmp/*')\n",
    "if not os.path.exists('./tmp'): #si le folder n'existe pas on le crée\n",
    "        os.makedirs('./tmp')\n",
    "        \n",
    "        \n",
    "test_length = 600\n",
    "MC1 = generate_random_cloud(np.pi/2, B_theta=np.pi/2)\n",
    "model = model.eval()\n",
    "\n",
    "ans_list = []\n",
    "N_B_thetas = 15\n",
    "B_thetas = np.pi*np.logspace(-6, -1, N_B_thetas, base=2)\n",
    "    \n",
    "std_theta = np.pi/6\n",
    "\n",
    "for trial in range(test_length):\n",
    "    theta = np.clip(std_theta *  np.random.randn(), -np.pi/4, np.pi/4)\n",
    "\n",
    "    # MC generation\n",
    "    B_theta = B_thetas[random.randint(0, N_B_thetas-1)]\n",
    "\n",
    "    MC1 = generate_random_cloud(np.pi/2, B_theta=B_theta)\n",
    "    MC2 = generate_random_cloud(np.pi/2 - theta, B_theta=B_theta)  # if shift = 2\n",
    "\n",
    "    varimgmc2 = data_transform(Image.open(MC2))\n",
    "    #varimgmc2 = data_transform(Image.open('16_clouds_easy/0.0/B0 1.40625.png'))\n",
    "    varimgmc2 = Variable(varimgmc2).cuda()\n",
    "    varimgmc2 = varimgmc2.unsqueeze(0)\n",
    "    \n",
    "    net_ans = model(varimgmc2)\n",
    "    pred = net_ans.data.max(1)[1] #prediction\n",
    "    #print(pred)\n",
    "    #correct = (np.sign(theta) > 0) and (pred[0]>8)\n",
    "    if np.sign(theta) > 0 and pred[0] > 8 :\n",
    "        correct = True\n",
    "    if np.sign(theta) < 0 and pred[0] <= 8:\n",
    "        correct = True\n",
    "    else :\n",
    "        correct = False\n",
    "    print('At trial ', trial, 'Angle=', '%3.3f' % (theta*180/np.pi), 'answer is ', pred[0], '(correct=', correct, '); bandwidth=', '%.3f' % (B_theta*180/np.pi))\n",
    "\n",
    "    # Output shape per trial is : trial number, shift direction, answered shift and b_theta\n",
    "    if pred[0] >8 :\n",
    "        ans_list.append([trial, theta, 'left', B_theta])\n",
    "    if pred[0] <= 8 :\n",
    "        ans_list.append([trial, theta, 'right', B_theta])\n",
    "\n",
    "#cleanup temp\n",
    "for f in files:\n",
    "    os.remove(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "pickle.dump(ans_list, open('./psychophysics_data/Psy_discrim_final_%s.p' % exp_info, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varimgmc2 = data_transform(Image.open('16_clouds_easy/2.722713633111154/B0 10.928413651643268.png'))\n",
    "varimgmc2 = Variable(varimgmc2)\n",
    "varimgmc2 = varimgmc2.unsqueeze(0)\n",
    "\n",
    "net_ans = model(varimgmc2)\n",
    "print(net_ans.data.max(1)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
